\section{Параллельный алгоритм глобального поиска}
Рассмотрим задачу поиска глобального минимума \(N\)-мерной функции \(\phi(y)\) в гиперинтервале \(D=\{y\in R^N:a_i\leqslant x_i\leqslant{b_i}, 1\leqslant{i}\leqslant{N}\}\). Будем предполагать, что функция удовлетворяет условию Липшица с априори неизвестной константой \(L\).
\begin{equation}
\label{task}
\phi(y^*)=\min\{\phi(y):y\in D\}
\end{equation}
\begin{equation}
\label{lip}
|\phi(y_1)-\phi(y_2)|\leqslant L\Vert y_1-y_2\Vert,y_1,y_2\in D,0<L<\infty
\end{equation}
\par
Существует ряд способов адаптации эффективных одномерных алгоритмов для решения многомерных задач, см., например, методы диагонального \cite{sergKvaDiaPaper} или симплексного \cite{zilinsk} разбиения области поиска. В данной работе мы будем использовать подход, основанный на идее редукции размерности с помощью кривой Пеано \(y(x)\), непрерывно и однозначно отображающей отрезок вещественной оси \([0,1]\) на \(n\)-мерный куб 
\begin{displaymath}
\label{cube}
\lbrace y\in R^N:-2^{-1}\leqslant y_i\leqslant 2^{-1},1\leqslant i\leqslant N\rbrace=\{y(x):0\leqslant x\leqslant 1\}
\end{displaymath}
\par
Вопросы численного построения отображений типа кривой Пеано и соответствующая теория подробно рассмотрены в \cite{strSergOptBook}. Здесь же отметим, что численно построенная развертка является приближением к теоретической кривой Пеано с точностью порядка \(2^{-m}\), где \(m\) –-- параметр построения развертки. Использование подобного рода отображений позволяет свести многомерную задачу к одномерной задаче
\begin{displaymath}
\label{oneDimTask}
\phi(y^*)=\phi(y(x^*))=\min\{\phi(y(x)):x\in [0,1]\}
\end{displaymath}
\par
Важным свойством является сохранение ограниченности относительных разностей функции: если функция \(\phi(y)\) в области \(D
\) удовлетворяла условию Липшица, то функция \(\phi(y(x))\) на интервале \([0,1]\) будет удовлетворять равномерному условию Гельдера
\begin{displaymath}
\label{holder}
|\phi(y(x_1))-\phi(y(x_2))|\leqslant H{|x_1-x_2|}^{\frac{1}{N}},x_1,x_2\in[0,1]
\end{displaymath}
где константа Гельдера \(H\) связана с константой Липшица \(L\) соотношением 
\begin{displaymath}
H=4Ld\sqrt{N},d=\max\{b_i-a_i:1\leqslant i\leqslant N\}
\end{displaymath}
\par
Поэтому, не ограничивая общности, можно рассматривать минимизацию одномерной функции  \(f(x)=\phi(y(x)), x\in[0,1]\), удовлетворяющей условию Гельдера.
\par
Рассматриваемый алгоритм решения данной задачи предполагает построение последовательности точек \(x_k\), в которых вычисляются значения минимизируемой функции \(z_k = f(x_k)\). Процесс вычисления значения функции (включающий в себя построение образа \(y_k=y(x_k))\) будем называть испытанием, а пару \((x_k,z_k)\) --- результатом испытания. Множество пар \(\{(x_k,z_k)\}, 1\leqslant k\leqslant n\) составляют поисковую информацию, накопленную методом после проведения \(n\) шагов. В нашем распоряжении имеется \(p\geqslant 1\) вычислительных элементов и в рамках одной итерации метода мы будем проводить \(p\) испытаний одновременно. Обозначим \(k(n)\) общее число испытаний, выполненных после \(n\) параллельных итераций.
\par
На первой итерации метода испытание проводится в произвольной внутренней точке \(x_1\) интервала \([0,1]\). Пусть выполнено \(n\geqslant 1\) итераций метода, в процессе которых были проведены испытания в \(k = k(n)\) точках \(x_i, 1\leqslant i\leqslant k\). Тогда точки \(x^{k+1},\dotsc,x^{k+p}\) поисковых испытаний следующей \((n+1)\)-ой итерации определяются в соответствии с правилами:
\par
Шаг 1. Перенумеровать точки множества \(X_k=\{x^1,\dotsc,x^k\}\cup\{0\}\cup\{1\}\), которое включает в себя граничные точки интервала \([0,1]\), а также точки предшествующих испытаний, нижними индексами в порядке увеличения значений координаты, т.е.
\begin{displaymath}
0=x_0<x_1<\dotsc<x_{k+1}=1
\end{displaymath}
\par
Шаг 2. Полагая \(z_i=f(x_i),1\leqslant i\leqslant k\), вычислить величины 
\begin{equation}
\label{step2}
\mu=\max_{1\leqslant i\leqslant k}\dfrac{|z_i-z_{i-1}|}{\Delta_i},
\begin{matrix}
    M = 
    \left\{
    \begin{matrix}
    r\mu,\mu>0 \\
    1,\mu=0
    \end{matrix} \right.
    \end{matrix}
\end{equation}
где \(r\) является заданным параметром метода, а \(\Delta_i=(x_i-x_{i-1})^\frac{1}{N}\).
\par
Шаг 3. Для каждого интервала \((x_{i-1},x_i),1\leqslant i\leqslant k+1\), вычислить характеристику в соответствии с формулами
\begin{equation}
\label{step3_1}
R(1)=2\Delta_1-4\dfrac{z_1}{M},R(k+1)=2\Delta_{k+1}-4\dfrac{z_k}{M}
\end{equation}
\begin{equation}
\label{step3_2}
R(i)=\Delta_i+\dfrac{(z_i-z_{i-1})^2}{M^2\Delta_i}-2\dfrac{z_i+z_{i-1}}{M},1<i<k+1
\end{equation}
\par
Шаг 4. Характеристики \(R(i),1\leqslant i\leqslant k+1\), упорядочить в порядке убывания 
\begin{equation}
\label{step4}
R(t_1)\geqslant R(t_2)\geqslant \dots \geqslant R(t_{k})\geqslant R(t_{k+1})
\end{equation}
и выбрать \(p\) наибольших характеристик с номерами интервалов \(t_j,1\leqslant j\leqslant p\).
\par
Шаг 5. Провести новые испытания в точках \(x_{k+j},1\leqslant j\leqslant p\), вычисленных по формулам
\begin{displaymath}
x_{k+j}=\dfrac{x_{t_j}+x_{t_j-1}}{2},t_j=1,t_j=k+1
\end{displaymath}
\begin{equation}
\label{step5}
x_{k+j}=\dfrac{x_{t_j}+x_{t_j-1}}{2}-\sign(z_{t_j}-z_{t_j-1})\dfrac{1}{2r}\left[\dfrac{|z_{t_j}-z_{t_j-1}|}{\mu}\right]^N,1<t_j<k+1
\end{equation}
\par
Алгоритм прекращает работу, если выполняется условие \(\Delta_{t_j}\leqslant \varepsilon\) хотя бы для одного номера \(t_j,1\leqslant j\leqslant p\); здесь \(\varepsilon>0\) есть заданная точность. В качестве оценки глобально-оптимального решения задачи  выбираются значения
\begin{equation}
f_k^*=\min_{1\leqslant i \leqslant k}f(x_i), x_k^*=\argmin_{1\leqslant i \leqslant k}f(x_i)
\end{equation}
\par
Теоретическое обоснование данного способа организации параллельных вычислений изложено в \cite{strGergrParOptBook}.
