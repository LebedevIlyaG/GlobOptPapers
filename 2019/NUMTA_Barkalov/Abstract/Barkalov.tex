% Latex-template for one-page abstract submissions.
% NUMTA2019 - Numerical Computations: Theory and Algorithms
% 15-21 June 2019, Le Castella - Isola Capo Rizzuto, Crotone (Italy)

\documentclass[oribibl]{llncs}

% Please, do not use your own macros/redefinitions.

\usepackage{fancyhdr}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%\usepackage[utf8x]{inputenc}
%\usepackage[english,russian]{babel}
%\usepackage{cmap}


\begin{document}
\cleardoublepage

\title{A new way to speedup in global optimization problems}
\author{Roman Strongin, Konstantin Barkalov, Semen Bevzuk}

%%% Please note that the first author is supposed to be the speaker.

\institute{University of Nizhni Novgorod, Nizhni Novgorod, Russia\\
\email{barkalov@vmk.unn.ru}}

\maketitle

\thispagestyle{fancy}

\textbf{Keywords.} Global optimization; multiextremal problems; Lipschitz constant.

 \vspace*{0.5cm}

%-----------------------------------------------------------------

The paper considers global optimization problems with a black-box objective function satisfying a Lipschitz condition. 
An important issue in this class of problems is reliable estimates of a priori unknown Lipschitz constant based on the results of the search trials. 
In fundamental work \cite{Book} various approaches have been proposed to take into account both global and local properties of the objective function. 
%В частности, показали свою перспективность  алгоритмы с использованием локальных оценок константы Липшица 
In particular, algorithms using local estimates of the Lipschitz constant have shown their promise \cite{Sergeyev10, Sergeyev16}.

This paper proposes a new way to account for the local properties of the objective function.
The proposed method is based on the use in the information-statistical global search algorithm \cite{Book} lower and upper estimates of the Lipschitz constant simultaneously. 
The rules of the new algorithm provide automatic switching between these two estimates, depending on the type of the objective function and on the search stage.

Proposed algorithm guarantees convergence to global minimizer. The results of solving several series of multiextremal test problems confirm both the global convergence of the new algorithm and its acceleration compared to the original one.

\textbf{Acknowledgements.}

This research was supported by the the Russian Science Foundation, project No.\,16-11-10150.

\vspace{0.5cm}

\begin{thebibliography}{4}

\bibitem{Book} Strongin R.G., Sergeyev Ya.D. (2000) \emph{Global optimization with non-convex constraints. Sequential and parallel algorithms}. Kluwer Academic Publishers, Dordrecht.

\bibitem{Sergeyev10} Lera D., Sergeyev Ya.D. (2010)  (2010) An information global minimization algorithm using the local improvement technique. \emph{J. Glob. Optim.}, Vol.~48(1), pp.~99--112.

\bibitem{Sergeyev16} Sergeyev Ya.D., Mukhametzhanov M.S., Kvasov D.E., Lera D. (2016) Derivative-free local tuning and local improvement techniques embedded in the univariate global optimization. \emph{J. Optim. Theory Appl.}, Vol.~171(1), pp.~186--208.

%\bibitem{Strongin18} Barkalov K., Strongin R. (2018) Solving a set of global optimization problems by the parallel technique with uniform convergence. \emph{J. Glob. Optim.}, Vol.~71(1), pp.~21--36.


\end{thebibliography}

\end{document}
