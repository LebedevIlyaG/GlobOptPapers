%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a proceedings volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{svproc}
%
% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\usepackage{graphicx}
\usepackage{marvosym}
\usepackage{amssymb}
\usepackage{cite}
%%%%%ДОБАВИЛ ДЛЯ РУССКОГО ТЕКСТА
\usepackage[utf8x]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{cmap}
%%%%%
% to typeset URLs, URIs, and DOIs
\usepackage{url}
\usepackage{hyperref}
\def\UrlFont{\rmfamily}

\def\orcidID#1{\unskip$^{[#1]}$}
\def\letter{$^{\textrm{(\Letter)}}$}

\begin{document}
\mainmatter              % start of a contribution
%
\title{Comparison of several sequential and parallel derivative-free global optimization algorithms}
%
\titlerunning{Comparison of several optimization methods}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Vladislav Sovrasov\letter \and Semen Bevzuk}
%
\authorrunning{Vladislav Sovrasov et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Vladislav Sovrasov and Semen Bevzuk}
%
\institute{Lobachevsky State University of Nizhni Novgorod, Russia \\
  \email{sovrasov.vlad@gmail.com, semen.bevzuk@gmail.com}
}

\maketitle              % typeset the title of the contribution

\begin{abstract}
This work considers several stochastic and deterministic derivative-free global optimization algorithms. In the first part of the paper popular sequential open-source solvers are compared against the Globalizer solver, which is developed at the Lobachevsky State University. The Globalizer is designed to solve problems with black-box objectives satisfying the Lipschitz condition and shows competitive performance with other similar solvers. The comparison is done on several sets of challenging multi-extremal benchmark functions. The second part of this work is devoted to comparison between the Globalizer and MIDACO solvers on systems with shared and distributed memory. MIDACO is a state-of-the-art global solver included to the TOMLAB optimization environment for MATLAB. Results of the benchmark show advantages of the Globalizer on small-dimensional, but sufficiently multi-extremal benchmark functions.
% We would like to encourage you to list your keywords within
% the abstract section using the \keywords{...} command.
\keywords{deterministic global optimization $\cdot$ stochastic global optimization
  $\cdot$ parallel numerical methods $\cdot$ derivative-free algorithms $\cdot$ black-box optimization}
\end{abstract}
%
\section{Introduction}

\begin{Russian}
Нелинейная глобальная оптимизация невыпуклых функций традиционно считается одной из самых трудных
задач математического программирования. Отыскание глобального минимума функции от нескольких переменных
зачастую оказывается сложнее, чем локальная оптимизация в тысячемерном пространстве. Для последней может оказаться достаточно
применения простейшего метода градиентного спуска, в то время как чтобы \textit{гаранитрованно} отыскать глобальный оптимум методам
оптимизации приходится накапливать информацию о поведении целевой функции во всей области поиска \cite{Jones2009,Paulavicius2011,Evtushenko2013,strSergGO}. В последнее время стали популярны
различные стохастические алгоритмы глобально оптимизации, прежде всего эволюционные \cite{Storn1997, SCHLUTER2009, KennedyEberhart1995}. Они имеют довольно простую структуру, позволяют решать задачи большой размерности, однако обеспечивают глобальную сходимость только в вероятностном смысле.

В данной работе рассмотрены open-source реализации девяти различных методов глобальной оптимизации.
Все алгоритмы были протестированы на наборе из 900 существенно многоэкстремальных функций, который был сгенерирован с
помощью специализированных генераторов задач \cite{Gaviano2003, grishaginClass}. Помимо сравнения последовательных алгоритмов, на подмножестве из 200 тестовых задач произведено сравнение солвера MIDACO \cite{Schlueter2012} и программной системы Globalizer \cite{globalizerSystem,Strongin2018} в условиях работы на суперкомпьютере Лобачевский.
\end{Russian}

\section{Related Work}

\begin{Russian}
Ранее в литературе рассмартивалось как сравнение между собой стохастических алгоритмов глобальной оптимизации \cite{Ali2005, JSSv060i06}, так и детерминированных \cite{posik2012, KVASOV2018245, Liberti2005}.
В них большинство современных методов изучены довольно детально, но упор в основном делается на последовательные алгоритмы, а основными критериями эффективности метода оптимизации является его надёжность и скорость сходимости. В большинстве работ в качестве набора тестовых функций берётся набор известных тестовых задач (например, функция Растригина, Ackley function и др.). Размер такого набора обычно не превышает 100 различных функций, некоторые из которых могут быть одноэкстремальны (как функция Розенброка).

В работе \cite{Beiranvand2017} сформулированы некие общие принципы, которых, по мнению авторов, следует придерживаться при сравнении методов оптимизации.
В частности, авторы говорят о преимуществах генераторов задач, позволяющих создать большие наборы задач, сводя случайные эффекты при сравнении к минимуму. В то же время, использование одного генератора может оказаться недостаточно для исчерпывающего сравнения методов. Чтобы частично преодолеть эту проблему, авторы \cite{Beiranvand2017} советуют использовать несколько генераторов различной природы и создавать наборы задач различной сложности.

Учитывая опыт предыдущих работ в области сравнения методов оптимизации, в данной работе будут использованы два генератора тестовых задач разной природы, с помощью которых сгенерировано 9 наборов по 100 задач разной сложности размерности от 2 до 5. Помимо сравнения последовательных методов, также в работе приводится сравнение эффективности двух параллельных алгоритмов.
\end{Russian}

\section{Statement of Multidimensional Global Optimization Problem}
In this paper, the core class of optimization problems, which can be solved using
global optimization methods, is formulated. This class involves the multidimensional global
optimization problems without constraints, which can be defined in the following way:
\begin{equation}
\label{eq:task}
\begin{array}{cr}\\
  \varphi(y^*)=\min\{\varphi(y):y\in D\}, \\
  D=\{y\in \mathbb{R}^N:a_i\leq y_i\leq{b_i}, 1\leq{i}\leq{N}\}
\end{array}
\end{equation}
with the given boundary vectors  $a$ and  $b$. It is supposed, that the objective function
\(\varphi(y)\) satisfies the Lipschitz condition
\begin{equation}
\label{eq:lip}
|\varphi(y_1)-\varphi(y_2)|\leq L\Vert y_1-y_2\Vert,y_1,y_2\in D,
\end{equation}
where \(L>0\) is the Lipschitz constant, and \(||\cdot||\) denotes the norm in \(\mathbb{R}^N\)
space.
\par
Usually, the objective function \(\varphi(y)\) is defined as a computational procedure,
according to which the value \(\varphi(y)\) can be calculated for any vector \(y\in D\)
(let us further call such a calculation \textit{a trial}). It is supposed that this procedure
is time-consuming.

\section{Review of Considered Optimization Methods}

\subsection{Parallel Algorithm of Global Search}
\subsubsection{Dimension Reduction with Evolvents}
Within the framework of the information-statistical global optimization theory,
the Peano space-filling curves (or evolvents) \(y(x)\) mapping the interval \([0,1]\)
onto an \(N\)-dimensional hypercube \(D\) unambiguously are used for the dimensionality
reduction \cite{sergeyevStronginLera2013, strongin1978, strSergGO}.
\par
As a result of the reduction, the initial multidimensional global optimization
problem (\ref{eq:task}) is reduced to the following one-dimensional problem:
\begin{equation}
\label{eq:oneDimTask}
\varphi(y(x^*))=\min\{\varphi(y(x)):x\in [0,1]\}.
\end{equation}
\par
It is important to note that this dimensionality reduction scheme transforms the % minimized
Lipschitzian function from (\ref{eq:task}) to the corresponding one-dimensional
function \(\varphi(y(x))\), which satisfies the uniform H{\"o}lder condition, i. e.
\begin{equation}
\label{eq:holder}
|\varphi(y(x_1))-\varphi(y(x_2))|\leq H{|x_1-x_2|}^{\frac{1}{N}}, x_1,x_2\in[0,1],
\end{equation}
where the constant $H$ is defined by the relation \(H=2L\sqrt{N+3}\), \(L\) is the Lipschitz
constant from (\ref{eq:lip}), and \(N\) is the dimensionality of the optimization problem
(\ref{eq:task}).
\par
The algorithms for the numerical construction of the Peano curve approximations are
given in \cite{strSergGO}.

\par
The computational scheme obtained as a result of the dimensionality reduction consists of the
following:
\begin{itemize}
  \item The optimization algorithm performs the minimization of the reduced one-dimensional
  function \(\varphi(y(x))\) from (\ref{eq:oneDimTask}),
  \item After determining the next trial point \(x\), a multidimensional image \(y\) is calculated by
using the mapping \(y(x)\),
  \item The value of the initial multidimensional function \(\varphi(y)\) is calculated at the point
\(y\in D\),
  \item The calculated value \(z=\varphi(y)\) is used further as the value of the reduced one-dimensional function \(\varphi(y(x))\) at the point \(x\).
\end{itemize}

\subsubsection{Algorithm of Global Search on Shared Memory}
\label{sub:ags}
Parallel optimization methods applied in Globalizer to solve the reduced problem
(\ref{eq:oneDimTask}) are based on the MAGS method, which can be presented as follows ---
see \cite{strongin1978}, \cite{strSergGO}.
\par
The initial iteration of the algorithm is performed at an arbitrary point \mbox{\(x^1\in(0,1)\)}.
Then, let us suppose that \(k\), \(k\ge 1\), optimization iterations have been completed already.
The selection of the trial point \(x^{k+1}\) for the next iteration is performed according to the
following rules.

\textit{Rule 1}. Renumber the points of the preceding trials by the lower indices in order of
increasing value of coordinates
$0=x_0<x_1<...<x_{k+1}=1$.

\textit{Rule 2}. Compute the characteristics \(R(i)\) for each interval \((x_{i-1},x_i),1\leq i\leq
k+1\).

\textit{Rule 3}. Determine the \(p\) intervals with the maximum characteristics $R(t_j)=\max_{1\leq i
\leq k+1}R(i),\: j=\overline{1,p}$.

\textit{Rule 4}. Execute new trials at points \(x^{k+j},\: j=\overline{1,p}\) located within intervals with
maximum characteristics from the previous step
  $x^{k+j}=d(x_{t_j}),\: j=\overline{1,p}$.

The stopping condition, which terminated the trials, is defined by the inequality
$\rho_{t_j}<\varepsilon,\: j=\overline{1,p}$
for the intervals with maximum characteristics from Step 3 and \(\varepsilon >0\) is the
predefined accuracy of the optimization problem solution. If the stopping condition is not satisfied,
the index \(k\) is incremented by \(p\), and the new global optimization iteration is executed.

This method is employed in Globalizer to organize parallel computations on shared memory: each of \(p\)
trials can be carried out on one of \(p\) local computation units.

The convergence conditions and exact formulas for descision rules $R(i)$ and $d(x)$ of the
described algorithm are given, for example, in \cite{strSergGO}.

\subsection{Parallel Algorithm on Distributed Memory Exploiting a Set of Evolvents}
\label{sub:parallel_evolvents}
\subsubsection{Rotated Evolvents}
One of the possible ways to overcome the negative effects of using a numerical
approximation of evolvent (it destroys the information about the neighbor points in $\mathbb{R}^N$ space)
consists in using the multiple mappings
\begin{equation}
  Y_L(x)=\left\{y^0(x),\ y^1(x),...,\ y^L(x)\right\}
\end{equation}
instead of single Peano curve $y(x)$ (see \cite{strSergGO}).
The building of a set of Peano curves by rotation of the evolvents around the coordinate origin is a distinctive feature was proposed in \cite{Gergel2009}. Taking into account the initial mapping, one can conclude that current implementation of the
method allows to build up to $N(N-1)+1$ evolvents for mapping the $N$-dimensional domain
onto the corresponding one-dimensional intervals. This method for building a set of mappings can be ``scaled'' easily to obtain more evolvents (up to
$2^N$) if necessary.

Using the multiple mapping allows solving initial problem (\ref{eq:task}) by parallel solving the
problems
\[
\min\{\varphi(y^s(x)):x\in [0,1]\}, 1\leqslant s\leqslant S
\]
on a set of intervals $[0,1]$ by the index method. Each one-dimensional problem is solved on a
separate processor. The trial results at the point \(x^k\) obtained for the problem being solved by
particular processor are interpreted as the results of the trials in the rest problems (in the
corresponding points \(x^{k_1},\dots,x^{k_S})\). In this approach, a trial at the point \(x^k \in
[0,1]\) executed in the framework of the \(s\)-th problem, consists in the following sequence of
operations:
\par
1. Determine the image \(y^k=y^s (x^k)\) for the evolvent \(y^s (x)\).
\par
2. Inform the rest of processors about the start of the trial execution at the point \( y^k\) (the
blocking of the point \(y^k\) ).
\par
3. Determine the preimages \(x{}^{k_s}  \in [0,1], 1\leqslant s\leqslant S\), of the point \(y^k\) and interpret the
trial executed at the point \(y^k \in D \) as the execution of the trials in the \(S\) points
\(x{}^{k_1} ,\dots,x{}^{k_s} \)
\par
4. Inform the rest of processors about the trial results at the point \(y^k\).
\par
The decision rules for the mentioned parallel algorithm, in general, are the same as the rules of the
sequential algorithm (except the method of the trial execution). Each processor has its own copy
of the software realizing the computations of the problem functions and the decision rule of the
index algorithm. For the organization of the interactions among the processors, the queues are
created on each processor, where the processors store the information on the executed iterations
in the form of the tuples: the processor number \(s\), the trial point \(x{}^{k_s}\).
The modifications of the method taking into account multiply criteria are given in \cite{GERGEL2017,Gergel2018}.
\par
The mentioned parallelization scheme was proposed in \cite{Gergel2009} and implemented in the Globalizer system with the use of MPI technology. Main
features of implementation consist in the following:
\begin{itemize}
  \item A separate MPI-process is created for each
 of \(S\) one-dimensional problems being solved, usually, one process per one processor
 employed.
 \item Each process can use $p$ threads to parallel execute $p$ trials, usually one thread per an accessible core.
\end{itemize}

\subsection{MIDACO Parallel Solver}
MIDACO (Mixed Integer Distributed Ant Colony Optimization) \cite{Schlueter2012} is a solver which implements the evolutionary algorithm
the ant colony optimization metaheuristic for continuous search domains. ACO was originally
proposed to solve the TSP, but later has been successfully adopted to solve mixed integer nonlinear programming problems \cite{SCHLUTER2009}.

The MIDACO solver utilizes reverse communication architecture \cite{Schlueter2012}.
Reverse communication means that the call of the objective function happens outside and independently of the MIDACO source code.
Relying on this feature the following distributed parallelization scheme was implemented:
\begin{enumerate}
  \item MIDACO runs at the master node and generates \(n \times p\) new trial points at each iteration.
  \item Each of \(n\) distributed computational nodes gets \(p\) points from the master and performs \(p\) parallel trials on local computing devices.
  \item Each of \(n\) distributed computational nodes sends \(p\) values of the objective function to the master.
\end{enumerate}

In this scheme all distributed communications were implemented using the MPI library.
Parallelism within a single node is powered by the OpenMP standard.

\subsection{Sequential Methods}
\begin{itemize}
  \item \textbf{Algorithm of Global Search}. Sequential version of the method described in Section \ref{sub:ags}.

  \item \textbf{Locally-based Algorithm of Global Search (AGS\(l\))} \cite{indexMethod}. It's a modification of
  the original AGS which make it more locally oriented by alternately using of two types of characteristics in the Rule 2 from the Section \ref{sub:ags}.

  \item \textbf{Multi Level Single Linkage} \cite{Kan1987StochasticGO}. MLSL is an improved multistart algorithm.
  It samples low-discrepancy starting points and does local optimizations from them. In contrast to the dummy multistart schemes
  MLSL uses some clustering heuristics to avoid multiple local descents to already explored local minimas.

  \item \textbf{DIRECT} \cite{Jones2009}. The algorithm is deterministic and recursively divides the search space and forms a tree of hyper-rectangles (boxes). DIRECT uses the objective function values and the Lipschitz condition (\ref{eq:lip}) to estimate promising boxes.

  \item \textbf{Locally-based DIRECT (DIRECT$l$)} \cite{Gablonsky2001}. It's a variation of DIRECT which pays less attention to non-promising boxes and therefore
  has less exploration power: it can converge faster on problems with few local minimas, but lost the global one in complicated cases.

  \item \textbf{Dual Simulated Annealing} \cite{XIANG1997216}. This stochastic method is a combination of the Classical Simulated Annealing and the Fast Simulated Annealing coupled to a strategy for applying a local search on accepted locations. It converges much faster than both parent algorithms, CSA and FSA.

  \item \textbf{Differential Evolution} \cite{Storn1997}. DE is an adaptation of the original genetic algorithm to
  the continuous search domain.

  \item \textbf{Controlled Random Search} \cite{Price1983}. The CRS starts with a set of random points and then defines
  the next trial point in relation to a simplex chosen randomly from a stored configuration of points. CRS in not an
  evolutional algorithm, although stores something like population and performs transformation resembling a mutation.

  \item \textbf{StoGO} \cite{Madsen1998}. StoGO is dividing the search space into smaller hyper-rectangles via a branch-and-bound approach,
  and searching them by a local-search algorithm, optionally including some randomness.

\end{itemize}

All the mentioned algorithms (except of AGS\(l\) which implemented in the Globalizer system)
are available in source codes as parts of wide-spread optimization packages.
AGS, DIRECT, DIRECT$l$, CRS, MLSL and StoGO are part of the NLOpt libray \cite{nlopt}. Differential Evolution and DSA can be found in
the latest version of the SciPy \cite{scipy} package for Python.

\section{Tools for Comparison of Global Optimization Algorithms}
\begin{Russian}

Использование сгенерированных некоторыми случайными механизмами
наборов тестовых задач с известными решениями является одним из общепринятых подходов
к сравнению алгоритмов оптимизации \cite{Beiranvand2017}. В данной работе
будем использовать два генератора тестовых задач, порождающих задачи различной природы \cite{grishaginClass, Gaviano2003}.

Обозначим набор задач, полученных с помощью первого генератора из \cite{grishaginClass} как \(F_{GR}\). Механизм построения задач \(F_{GR}\),
не предусматривает контроль за сложностью задач и количеством локальных оптимумов, однако известно, что порождаемые функции
являются существенно многоэкстремальными. Кроме того, задачи, порождаемые \(F_{GR}\) двухмерные. В данной работе будем использовать
100 случайно сгенерированных функций из класса \(F_{GR}\).

Генератор GKLS \cite{Gaviano2003} позволяет получать задачи заданной размерности и с заданным количеством экстремумов.
Кроме того GKLS позволяет регулировать сложность задач, уменьшая или увеличивая размер области притяжения глобального минимума.
В работе \cite{SergeyevKvasov2006} указаны параметры генератора, позволяющие породить наборы по 100 задач двух уровней сложности
(Simple и Hard) размерностей 2, 3, 4 и 5. Следуя примеру авторов генератора GKLS, будем использовать предложенные ими параметры и,
таким образом, добавим в тестовый ещё 800 задач различной размерности и сложности.

Будем считать, что тестовая задача решена, если метод оптимизации провёл очередное испытание \(y^k\) в
\(\delta\)-окрестности глобального минимума \(y^*\), т.е. $\left\|y^k-
y^*\right\|\leqslant \delta = 0.01\left\|b-a\right\|$, где \(a\) и \(b\) --- левая и правая границы гиперкуба из (\ref{eq:task}).
Если указанное соотношение не выполнено до истечения лимита на количество испытаний, то задача считается нерешённой.
Максимальный лимит на количество испытаний установлен для каждого класса задач, в соответствии с размерностью и сложностью (см. таблицу \ref{tab:limits}).

\begin{table}
\begin{center}
\caption{Trials limit for the each of test problems classes}
  \begin{tabular}{|l|{c}|}
    \hline
  Problems class & Trials limit\\
  \hline
  \(F_{GR}\) & 5000 \\
  \hline
  GKLS 2d Simple & 8000 \\
  \hline
  GKLS 2d Hard & 9000 \\
  \hline
  GKLS 3d Simple & 15000 \\
  \hline
  GKLS 3d Hard & 25000 \\
  \hline
  GKLS 4d Simple & 150000 \\
  \hline
  GKLS 4d Hard & 250000 \\
  \hline
  GKLS 5d Simple & 350000 \\
  \hline
  GKLS 5d Hard & 600000 \\
  \hline
  \end{tabular}
  \label{tab:limits}
\end{center}
\end{table}

В качестве характеристик метода оптимизации на каждом из классов будем рассматривать среднее число
испытаний, затраченное для решения одной задачи, и количество решённых задач. Чем меньше число испытаний, тем быстрее метод сходится
к решению, а значит и меньше обращается к потенциально трудоёмкой процедуре вычислений целевой функции.
Количество решённых задач говорит о надёжности метода с заданными параметрами на решаемом классе тестовых задач.
Чтобы сделать величины, характеризующие надёжность и скорость сходимости, независимыми при подсчёте среднего количества испытаний учитывались только решённые задачи.
\end{Russian}

\section{Results of Numerical Experiments}
\subsection{Results of Sequential Algorithms}
\begin{Russian}

Результаты тех или иных алгоритмов на различных классах задач напрямую зависят от
настроек алгоритмов. В большинстве случаев авторы программных реализаций ориентируются на
задачи средней сложности и чтобы получить удовлетворительный результат при решении
существенно многоэкстремальных задач, требуется корректировка некоторых параметров.
При проведении сравнения были заданы следующие параметры для методов:
\begin{itemize}
  \item в методе AGS\(l\) параметр чередования глобального и локального правил вычисления характеристик был задан равным 5:1;
  \item в методах DIRECT и DIRECT\(l\) параметр \(\epsilon=10^{-4}\);
  \item в методе SDA параметр \(visit=2.72\).
\end{itemize}

Остальные параметры варьировались в зависимости от класса задач (см. таблицу \ref{tab:params}).

\begin{table}
\begin{center}
\caption{Class-specific parameters of optimization algorithms}
  \begin{tabular}{|l|{c}|{c}|{c}|}
    \hline
    & AGS, AGS\(l\) & CRS & DE\\
  \hline
  \(F_{GR}\) & \(r=3\) & popsize=150 & mutation=(1.1,1.9), popsize=60 \\
  \hline
  GKLS 2d Simple & \(r=4.6\) & popsize=200 & mutation=(1.1,1.9), popsize=60 \\
  \hline
  GKLS 2d Hard & \(r=6.5\) & popsize=400 & mutation=(1.1,1.9), popsize=60 \\
  \hline
  GKLS 3d Simple & \(r=3.7\) & popsize=1000 & mutation=(1.1,1.9), popsize=70 \\
  \hline
  GKLS 3d Hard & \(r=4.4\) & popsize=2000 & mutation=(1.1,1.9), popsize=80 \\
  \hline
  GKLS 4d Simple & \(r=4.7\) & popsize=8000 & mutation=(1.1,1.9), popsize=90 \\
  \hline
  GKLS 4d Hard & \(r=4.9\) & popsize=16000 & mutation=(1.1,1.9), popsize=100 \\
  \hline
  GKLS 5d Simple & \(r=4\) & popsize=25000 & mutation=(1.1,1.9), popsize=120 \\
  \hline
  GKLS 5d Hard & \(r=4\) & popsize=30000 & mutation=(1.1,1.9), popsize=140 \\
  \hline
  \end{tabular}
  \label{tab:params}
\end{center}
\end{table}

В таблицах \ref{tab:trials}, \ref{tab:solved} приведены результаты запуска методов оптимизации на рассматриваемых классах задач.
Методы DIRECT и AGS\(l\) показали наилучшую скорость сходимости на всех классах, причём AGS\(l\) уступает
DIRECT на задачах из классов Simple и обходит его на задачах классов Hard. Как видно из таблицы \ref{tab:solved},
самыми надёжными методами являются детерминированные: AGS, AGS\(l\), DIRECT и DIRECT\(l\). Из стохастических методов
самую высокую надёжность демонстрируют MLSL и SDA.

\begin{table}
\begin{center}
\caption{Averaged number of trials executed by sequential methods for solving the test
optimization problems}
\resizebox{\textwidth}{!}{%
  \begin{tabular}{|l|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|}
    \hline
    & AGS & AGS\(l\) & CRS & DIRECT & DIRECT\(l\) & MLSL & SDA & DE & StoGO \\
  \hline
  \(F_{GR}\)     & 193.1 &  \textbf{158.3} & 400.3 & 182.3 & 214.9 & 947.2 & 691.2 & 1257.3 & 1336.8 \\
  \hline
  GKLS 2d Simple &  254.9 & 217.6 & 510.6 & \textbf{189.0} & 255.2 & 556.8 & 356.3 & 952.2 & 1251.5 \\
  \hline
  GKLS 2d Hard   &  728.7 & \textbf{488.0} & 844.7 & 985.4 & 1126.7 & 1042.5 & 1637.9 & 1041.1 & 2532.2 \\
  \hline
  GKLS 3d Simple &  1372.1 & 1195.3 & 4145.8 & \textbf{973.6} & 1477.8 & 4609.2 & 2706.5 & 5956.94 & 3856.1 \\
  \hline
  GKLS 3d Hard   &  3636.1 & \textbf{1930.5} & 6787.0 & 2298.7 & 3553.3 & 5640.1 & 4708.4 & 6914.3 & 7843.2 \\
  \hline
  GKLS 4d Simple &  26654.1 & 11095.7 & 37436.8 & \textbf{7824.3} & 15994.1 & 41514.3 & 21417.9 & 19157.7 & 59895.4 \\
  \hline
  GKLS 4d Hard   &  54536.8 &  \textbf{23167.8} &  73779.3 &  23204.4 &  54489.9 &  80247.2 &  68815.5 &  27466.1 &  109328.1  \\
  \hline
  GKLS 5d Simple &  29810.0 & 11529.0 & 143575.0 & \textbf{7166.5} & 13970.5 & 52647.6 & 34255.3 & 73074.5 & 91580.4 \\
  \hline
  GKLS 5d Hard   &  113129.1 & 67652.7 & 165192.8 & \textbf{66327.4} & 164390.6 & 138766.2 & 116973.1 & 105496.9 & 155123.8 \\
  \hline
\end{tabular}}
  \label{tab:trials}
\end{center}
\end{table}

\begin{table}
\begin{center}
\caption{Number of test optimization problems solved by sequential methods}
  \begin{tabular}{|l|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|{c}|}
    \hline
    & AGS & AGS\(l\) & CRS & DIRECT & DIRECT\(l\) & MLSL & SDA & DE & StoGO \\
  \hline
  \(F_{GR}\)     &  100 & 100 & 76  & 100 & 100 & 97  & 96  & 96  & 67\\
  \hline
  GKLS 2d Simple &  100 & 100 & 85  & 100 & 100 & 100 & 100 & 98  & 90\\
  \hline
  GKLS 2d Hard   &  100 & 100 & 74  & 100 & 100 & 100 & 93  & 85  & 77 \\
  \hline
  GKLS 3d Simple &  100 & 97  & 75  & 100 & 100 & 100 & 89  & 86  & 44 \\
  \hline
  GKLS 3d Hard   &  100  & 99   & 72   & 100  & 99   & 100  & 88   & 77   & 43 \\
  \hline
  GKLS 4d Simple &  100 & 100 & 46  & 100 & 100 & 94  & 78  & 59  & 16 \\
  \hline
  GKLS 4d Hard   &  100 & 100 & 47  & 99  & 97  & 94  & 72  & 32  & 10  \\
  \hline
  GKLS 5d Simple &  100 & 100 & 68  & 100 & 100 & 98  & 100 & 77  & 9  \\
  \hline
  GKLS 5d Hard   &  97  & 99  & 42  & 100 & 90  & 79  & 84  & 48  & 8 \\
  \hline
  \end{tabular}
  \label{tab:solved}
\end{center}
\end{table}

\subsection{Results of Parallel Algorithms}

The computational experiments with parallel algorithms have been carried out on the Lobachevsky supercomputer at
State University of Nizhni Novgorod. A computational node includes 2 Intel
Sandy Bridge E5-2660 2.2 GHz processors, 64 GB RAM. Each CPU has 8 cores (i. e. total 16
cores were available per a node). All computational nodes are working under CentOS Linux 7.2.
All considered algorithms are implemented using C++ and compiled by GCC 4.8.5.

Сравнение двух параллельных алгоритмов, реализованных в системах Globalizer и MIDACO
было проведено на четырёхмерных задачах GKLS, т.к. задачи большей размерности не поддерживаются
бесплатной версией MIDACO. Как и в случае с последовательными алгоритмами, для кадого класса задач
были изменены параметры методов. Для MIDACO параметр \(focus = -1\). В случае с Globalizer параметр
\(r\) был выбран следуя таблице \ref{tab:params}. С удвоением количества задействованных развёрток
этот параметр уменьшался на 0.3, поскольку увеличение количества развёрток увеличивает и надёжность метода из секции \ref{sub:parallel_evolvents}
(подробнее см. \cite{SOVRASOV2018}).

Если считать, что затраты на параллелизм пренебрежимо малы по сравнению с затратами на вычисление целевых функций в задачах оптимизации, то ускорение по времени от использования параллельного метода будет равно ускорению по итерациям. Однако, в действительности это предположение справедливо,
тлолько если вычисление значения целевой функции достаточно трудоёмко. Во всех численных экспериментах время вычисления целевой функции занимает примерно $2\times 10^{-3}$с.

In Table~\ref{tab:iterations}, an averaged number of iterations when solving 100 problems from
each considered class is presented.
The number of iterations is reduced considerably with increasing the number of nodes and the
number of threads on each node. В скобках также указано количество решённых задач в каждом классе.
Globalizer решает практически все задачи в обоих классах, в то время как MIDACO не решает многие задачи из класса GKLS 4d Hard.
Стоит ещё отметить, что с ростом числа узлов надёжность MIDACO падает на обоих классах задач, в то время как надёжность Globalizer остаётся стабильной.

\begin{table}
  \centering
  \caption{Averaged numbers of iterations executed by the parallel algorithm for solving the test
optimization problems}
  \label{tab:iterations}
  \begin{tabular}{cccccccc}
    \cline{3-8}\noalign{\smallskip}
    \multicolumn{2}{c}{  } & \textit{p} & \multicolumn{2}{c}{Globalizer} & &
\multicolumn{2}{c}{MIDACO}   \\
    \noalign{\smallskip} \cline{4-5} \cline{7-8}  \noalign{\smallskip}
    \multicolumn{2}{c}{  } & & \textit{Simple} & \textit{Hard} & & \textit{Simple} &
\textit{Hard}  \\
    \noalign{\smallskip}\hline
    I & \textbf{1 cluster node}
      & \textit{1} &   25270 (100)  & 55180 (99) & & 27645 (98) & 72068 (71)  \\
    &  & \textit{16} & 1765 (100)  & 3714 (100) & &  1640 (97) & 4304 (70) \\
    \hline \noalign{\smallskip}
II  & \textbf{2 cluster nodes}  %\multirow{3}{*}{}
  & \textit{1} & 13056 (100) & 22938 (99) & & 10558 (89) & 27128 (73) \\
&   & \textit{16} & 732 (100) & 1759 (100)  &  & 1130 (92) & 2254 (73) \\
    \hline \noalign{\smallskip}
III & \textbf{4 cluster nodes} %\multirow{3}{*}{}
  & \textit{1}  & 5016 (100) & 12703 (100) & & 5777 (94) & 15980 (75) \\
& & \textit{16} & 367 (100) & 776 (100) & & 529 (88) &  1264 (66) \\
    \hline \noalign{\smallskip}
VI & \textbf{8 cluster nodes} %\multirow{3}{*}{}
  & \textit{1}  & 2103 (100) & 5063 (100) & & 2847 (97) & 9853 (83)\\
& & \textit{16} & 145 (100)  & 310 (100)  & & 272 (83) & 774 (57)\\
    \hline \noalign{\smallskip}
V & \textbf{12 cluster nodes} %\multirow{3}{*}{}
  & \textit{1}  & 1155 (100) & 2399 (100) & & 2233 (98) & 6022 (86) \\
& & \textit{16} & 76 (100)  & 159 (100)  & & 168 (87) & 393 (53)\\
    \noalign{\smallskip}\hline
  \end{tabular}
\end{table}

Среднее ускорение по итерациям и среднее ускорение по времени (в скобках) приведены в таблице \ref{tab:speedup}.
В первой строке таблицы приведено среднее количество итераций и среднее время решения задачи в
последовательном режиме (в скобках). MIDACO для при параллельных вычислениях использует
меньшее количество коммуникаций, поэтому показатели ускорения монотонно возрастают с ростом количества
вычислительных узлов. В Globalizer каждый узел должен переслать результаты проведения итерации
всем другим узлам и с увеличением количества узлов и количества рабочих потоков на каждом узле
эффективность распараллеливания падает. Это можно видеть в таблице \ref{tab:speedup}, когда при переходе от 4х
узлов к 8 ускорение по времени при использовании 16 потоков упало. В случае одного потока на узел
ускорение обоих методов оптимизации примерно одинаковое. Однако стоит заметить, что Globalizer выполняет
меньше испытаний и при \(p=1\) тратит гораздо меньше времени на решение всех задач.
С ростом количества узлов и потоков MIDACO догоняет Globalizer по среднему времени решения задачи,
однако надёжность при этом падает.

Аномальное сверхлинейное ускорение по времени
MIDACO на классе GKLS 2d Hard при использовании 8 и 12 узлов можно объяснить тем, что, согласно таблице
\ref{tab:iterations}, MIDACO решил больше задач в параллельном режиме, чем в последовательном, а значит, на
меньшем количестве задач работал до исчерпания лимита испытаний.

\begin{table}
  \centering
  \caption{Speedup of parallel computations executed by the parallel algorithm}
  \label{tab:speedup}
  \begin{tabular}{cccccccc}
    \cline{3-8}\noalign{\smallskip}
    \multicolumn{2}{c}{  } & \textit{p} & \multicolumn{2}{c}{Globalizer} & &
\multicolumn{2}{c}{MIDACO}   \\
    \noalign{\smallskip} \cline{4-5} \cline{7-8}  \noalign{\smallskip}
    \multicolumn{2}{c}{  } & & \textit{Simple} & \textit{Hard} & & \textit{Simple} &
\textit{Hard}  \\
    \noalign{\smallskip}\hline
I  & \textbf{1 cluster node}  %\multirow{3}{*}{}
    & \textit{1}   & 25270 (27.3s) & 55180 (61.8s) & & 27645 (32.2s) & 72068 (132.5s)  \\
  &  & \textit{16} & 14.3(11.7) & 14.9(12.6)  & &  16.9(14.4) & 16.7(14.4) \\
  \hline \noalign{\smallskip}
II  & \textbf{2 cluster nodes}  %\multirow{3}{*}{}
  & \textit{1}      &   1.9(1.9) & 2.4(2.2)  & & 2.6(1.7) & 2.7(2.3) \\
  &   & \textit{16} & 34.5(20.4) & 31.4(18.8) & & 24.5(18.8) & 32.0(29.1) \\
    \noalign{\smallskip}\hline	\noalign{\smallskip}
III  & \textbf{4 cluster nodes}  %\multirow{3}{*}{}
& \textit{1}      & 5.0(4.6) & 4.3(4.1) & & 4.8(3.9) & 4.5(4.4) \\
&   & \textit{16} & 68.8(23.7) & 71.2(25.8) & & 52.3(32.9) & 57.0(50.2) \\
  \noalign{\smallskip}\hline	\noalign{\smallskip}
VI & \textbf{8 cluster nodes} %\multirow{3}{*}{}
& \textit{1}    & 12.0(8.7) & 10.9(8.3) & & 9.7(8.2)    & 7.3(9.0)    \\
& & \textit{16} & 174.1(4.7) & 177.8(5.3) & & 101.6(51.6) & 93.1(84.1) \\
    \noalign{\smallskip}\hline
    V & \textbf{12 cluster nodes} %\multirow{3}{*}{}
    & \textit{1}    & 21.9(11.4)  & 23.0(12.8)  & & 12.4(11.1)  & 12.0(14.8)  \\
    & & \textit{16} & 333.5(2.7) & 347.9(3.0) & & 164.5(82.0) & 183.2(129.7) \\
        \noalign{\smallskip}\hline
  \end{tabular}
\end{table}

\section{Conclusions}

В статье были рассмотрены несколько последовательных и параллельных алгоритмов глобальной оптимизации.
Было проведено сравнение эффективности их работы на множестве тестовых задач, по результатам которого можно сделать
следующие выводы:
\begin{itemize}
  \item методы AGS\(l\), реализованный в системе Globalizer показал скорость сходимости и надёжность на уровне \(DIRECT\) и
  превосходит многие другие алгоритмы, реализации которых есть в открытом доступе;
  \item стохастические методы оптимизации проигрывают детерминированным по скорости сходимости и надёжности. Особенно
  сильно это проявляется на более сложных многоэкстремальных задачах;
  \item параллельная версия системы Globalizer демонстрирует хорошие показатели ускорения по времени при работе на нескольких узлах,
  на каждом из которых вычисляется одно значение целевой за итерацию. При решении задач с быстро вычислимой целевой функцией и
  использовании многопоточности на узлах показатели ускорения системы Globalizer деградируют с увеличением количества узлов;
  \item система MIDACO больше всего подходит для несложных глобальных задач, целевые функции в которых могут быть быстро вычислимы.
  В таком случае MIDACO достаточно надёжна и обеспечивает линейное ускорение с ростом количества узлов и параллельно выполняемых потоков на них.
\end{itemize}

\end{Russian}

\section*{Acknowledgements}
The study was supported by the Russian Science Foundation, project No 16-11-
10150.

% ---- Bibliography ----
%
\bibliographystyle{spmpsci}
\bibliography{bibliography}{}

\end{document}
