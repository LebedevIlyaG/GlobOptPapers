\documentclass{llncs}


\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage[misc,geometry]{ifsym}

\usepackage{amsmath}
\usepackage{enumitem}
%\usepackage{amsfonts}
%\usepackage{amssymb}
%\usepackage{epstopdf}
%\usepackage{epsfig}

\usepackage[utf8x]{inputenc}
\usepackage[english,russian]{babel}



\begin{document}

\mainmatter 

\title{Parallel Global Optimization for Non-Convex Mixed-Integer Problems
\thanks{This study was supported by the Russian Science Foundation, 
project No.\,16-11-10150.}}
\author{Konstantin Barkalov \and Ilya Lebedev %\Letter 
\\
\email{ \{konstantin.barkalov,ilya.lebedev\}@itmm.unn.ru}}

\institute{
Lobachevsky State University of Nizhni Novgorod, Nizhni Novgorod, Russia
}

\maketitle

\begin{abstract}

In the present paper, the mixed-integer global optimization problems are considered. A novel 
parallel algorithm for solving the problems of this class based on the information-statistical 
approach to solving the continuous global optimization problems has been proposed. 
The comparison of this algorithm with known analogs demonstrating the efficiency of the 
developed approach has been conducted. 
%Russian
Предложенный алгоритм допускает эффективное использование graphics accelerators. 
Проведены вычислительные эксперименты при решении серии из 100 multiextremal mixed-integer problems, которые подтверждают хорошее ускорение алгоритма с использованием GPU. 

\keywords global optimization, non-convex constraints, mixed-integer problems.

\end{abstract}

\section{Introduction}\label{sec:intro}

In the present paper, the global optimization problems and the method of solving these ones are 
considered. The global optimization problems are the computation-costly ones since the global 
optimum is an integral characteristic of the problem being solved and requires the investigation 
of the whole search domain. 
As a result, the search of the global optimum is reduced to the construction of a coverage (in general, a nonuniform one) of the space of parameters. 
The problems, in which some parameters can take the integer values only (mixed-integer global 
optimization problems) are of special interest because for these ones it is more difficult to build 
the estimates of the optimum as compared to the continuous problems.

The situation when some parameters are featured by the discreteness or integerness is frequent in applied problems. As a rule, the integer parameters take a small number of values and may denote, for example, the trademarks of the materials used, the variant of typical layouts of components, etc.

A lot of publication have been devoted to the methods of solving the mixed-integer problems 
(see, for example, the reviews~\cite{Burer,Boukouvala}). The well known deterministic 
methods of solving the problems of this class are based, as a rule, on the Branch-and-Bound 
approach \cite{Belotti} or on the Branch-and-Reduce one \cite{Vigerske}. Also, a number of the metaheuristic and genetic 
algorithms are known, which are based one way or another on the random search concept \cite{Deep,Schluter}.

In the present study, we proposed a novel parallel method for solving the mixed-integer 
problems based on the information-statistical approach to solving the global optimization 
problems \cite{Strongin2000,Strongin2013}. 
%Russian
В рамках данного подхода 
\begin{itemize}
	\item 
	решение многомерных задач сводится  к решению эквивалентных им одномерных, cоответствующая редукция основана на использовании space-filling curves;
	\item 
	при решении constrained optimization problems каждое ограничение учитывается и обрабатывается отдельно, штрафные функции не используются;
	\item 
	распараллеливание процесса поиска осуществляется за счет одновременного вычисления на каждой итерации нескольких значений целевой функции в разных точках search domain.	
\end{itemize}

Текст статьи, отражающей результаты проведенного исследования, построен следующим образом. 
В разделе 2 дано краткое описание описание схемы редукции размерности с использованием space-filling curves, а также описана индексная схема учета ограничений. Здесь же приведена формулировка параллельного индексного алгоритма для решения задач непрерывной глобальной оптимизации.
В разделе 3 предложен подход к обобщению параллельного индексного алгоритма с целью решения mixed-integer problems. Приведен способ, позволяющий свести решение mixed-integer problem к решению набора задач непрерывной оптимизации, которое может выполняться параллельно. 
Раздел 4 содержит результаты численных экспериментов. Здесь производится сравнение последовательной версии алгоритма с известными аналогами, а также показана эффективность параллельных CPU- и GPU-версий алгоритма при решении серии multiextremal mixed-integer problem.  
Section 5 concludes the paper.


\section{Global optimization algorithm and dimension reduction}

A constrained global optimization problem can be formulated as follows
%Let us consider the $N$-dimensional global optimization problem
\begin{gather}\label{problem}
\varphi(y^\ast)=\min{\left\{\varphi(y):y\in D, \; g_i(y)\leq 0, \; 1 \leq i \leq m\right\}},\\
D=\left\{y\in R^N: a_j\leq y_j \leq b_j, 1\leq j \leq N \right\}.\label{D}
\end{gather}
The objective function $\varphi(y)$ (hereafter denoted by $g_{m+1}(y)$) and the left-hand 
sides $g_i(y), \; 1\leq i \leq m,$ of the constraints satisfy the Lipschitz condition 
\[
\left|g_i(y_1)-g_i(y_2)\right|\leq L_i\left\|y_1-y_2\right\|, \;1\leq i\leq m+1, \; y_1,y_2 \in D,\;
\]
with a priori unknown constants $L_i, \; 1 \leq i \leq m+1,$ and may be multiextremal. It is 
assumed that the functions $g_i(y)$ are defined and computable only at the points $y \in D$ 
satisfying the conditions
\begin{equation}\label{g_k}
g_k(y) \leq 0, \; 1 \leq k < i.
\end{equation}

By employing the continuous single-valued Peano-Hilbert curve $y(x)$ mapping the unit interval 
$[0,1]$ on the $x$-axis onto the $N$-dimensional domain (\ref{D}), it is possible to find the 
minimum in (\ref{problem}) by solving the one-dimensional problem
\[
\varphi(y(x^\ast))=\min \left\{\varphi(y(x)): x \in [0,1], \; g_i(y(x))\leq 0, \; 1 \leq i \leq m\right\}.
\]
Algorithms for numerical construction of Hilbert curve approximation (\textit{evolvent}) are 
considered in \cite{Strongin2013}. These evolvents are fractals generated by an iterative
process, that fill in the hypercube $D$ with accuracy $2^{-m}$, where integer $m>0$ is the evolvent construction parameter. 

Problems of numerical construction of Peano-type space filling curves and the corresponding theory are considered in detail in \cite{Strongin2000,Strongin2013}. Examples of the evolvent with different $m$ in two dimensions are given in Fig.~\ref{evolvents}.

\begin{figure}
\begin{minipage}{0.49\linewidth}
\center{\includegraphics[width=1.0\linewidth]{fig1b.JPG} \\ (a)}
\end{minipage}
\begin{minipage}{0.49\linewidth}
\center{\includegraphics[width=1.0\linewidth]{fig1c.JPG} \\ (b)}
\end{minipage}
\caption{Evolvents in two dimensions with (a) $m=4$ and (b) $m=5$}
\label{evolvents}
\end{figure}


Due to (\ref{g_k}) the functions $g_i(y(x))$ are defined 
and computable in the subranges 
\[
Q_1=[0,1], \; Q_{i+1}=\left\{x \in Q_i : g_i(y(x)) \leq 0 \right\}, \; 1 \leq i \leq m.
\]

These conditions allows us to introduce a classification of the points $x \in [0,1]$ according to 
the number $\nu (x)$ of the constraints computed at this point. The \textit{index} $\nu(x)$ can 
also be defined by the conditions
\begin{equation}\label{nu}
g_i(y(x)) \leq 0, \; 1 \leq i < \nu, \; g_\nu(y(x))>0,
\end{equation}
where the last inequality is inessential if $\nu=m+1$.

In the dimensionality reduction scheme considered here, a multidimensional problem with 
Lipschitzian functions is juxtaposed with a one-dimensional problem, where the corresponding 
functions satisfy uniform H{\"o}lder condition (see \cite{Strongin2013}), i.e.,
\[
\left|g_i(y(x_1))-g_i (y(x_2))\right| \leq H_i \left|x_1-x_2 \right|^{1/N}, \; x_1,x_2\in [0,1], \; 
1\leq i \leq m+1.
\]
Here, $N$ is the dimensionality of the initial multidimensional problem and the coefficients 
$H_i$ are related to the Lipschitz constant $L_i$ of the initial problem as $H_i \leq 2L_i 
\sqrt{N+3}$.

Thus, \textit{a trial} at a point $x^k \in [0,1]$ executed at the $k$-th iteration of the algorithm 
will consist of the following sequence of operations:
\begin{itemize}
	\item Determine the \textit{image} $y^k=y(x^k)$ in accordance with the mapping 
$y(x)$;
	\item Compute the values $g_1(y^k),..., g_\nu(y^k),$ where $\nu = \nu(x^k)$ is from 
(\ref{nu}). 
\end{itemize}
The dyad 
\begin{equation} \label{trial_result}
 \{ \nu=\nu(x^k), \; z^k=g_\nu(y(x^k)) \} 
\end{equation}
will be referred to as the \textit{trial outcome}.

An efficient parallel index algorithm (PIA) for solving the constrained global optimization problem (\ref{problem}) has been developed at University of Nizhni Novgorod. The scheme of the algorithm is as follows.

Suppose we have $p \geq 1$  computational elements (e.g., accelerator cores), which can be used to run $p$ trials simultaneously. In the first iteration of the method, $p$ trials are run in parallel at various random points $x^i\in(0,1)$, $1\leq i \leq p$. 
Suppose $n \geq 1$  iterations of the method have been completed, and as a result of which, trials were carried out in $k=k(n)$ points $x^i, 1\leq i \leq k$. Then the points $x^{k+1},...,x^{k+p}$  of the search trials in the next $(n+1)$-th iteration will be determined according to the rules below.

\begin{enumerate}
\item 
Renumber the points $x^1,...,x^k$ from previous iterations with lower indices, lowest to highest coordinate values, i.e.
\begin{equation}\label{Eq:17}
0=x_0<x_1<...<x_i<...<x_k<x_{k+1}=1,
\end{equation}
and match them with the values $z_i=g_\nu(y(x_i))$, $\nu=\nu(x_i)$, $1 \leq i \leq k$, from (\ref{trial_result}), calculated at these points; points $x_0=0$ и $x_{k+1}=1$ are introduced additionally; the values $z_0$ и $z_{k+1}$ are indeterminate.
\item
Classify the numbers $i,1\leq i \leq k$, of the trial points from (\ref{Eq:17}) by the number of problem constraints fulfilled at these points, by building the sets
\begin{equation}\label{Eq:18}
I_\nu = \left\{i: 1 \leq i \leq k,\ \nu = \nu(x_i)\right\},\ 1 \leq \nu \leq m+1,
\end{equation}
containing the numbers of all points $x_i,1\leq i \leq k$, with the same values of $\nu$. The end points $x_0=0$ and $x_{k+1}=1$ are interpreted as those with zero indices, and they are matched to an additional set $I_0={0,k+1}$. 

Identify the maximum current value of the index
\begin{equation}\label{Eq:19}
M=\max \left\{\nu = \nu(x_i), \ 1\leq i \leq k\right\}.
\end{equation}
\item
For all values of $\nu, \ 1\leq \nu \leq m+1$, calculate the values  
\begin{equation}\label{Eq:20}
\mu_\nu = \max \left\{ \frac{\left|z_i-z_j\right|}{\left(x_i-x_j\right)^{1/N}} : i,j \in I_\nu, j<i\right\}.
\end{equation}
If the set $I_\nu$ contains less than two elements or $\mu_\nu$ from (\ref{Eq:20}) equals zero, then assume $\mu_\nu=1$.
\item
For all non-empty sets $I_\nu$, $1 \leq \nu \leq m+1$, determine the values
\begin{equation}\label{Eq:21}
  z^\ast_\nu =  
   \begin{cases}
    -\epsilon_\nu,  \nu < M, \\
    \min{\left\{g_\nu(x_i):i\in I_\nu\right\}}, \nu = M,
   \end{cases}
\end{equation}
where $M$ is the maximum current value of the index, and the vector
\begin{equation}\label{Eq:22}
\epsilon _R=\left(\epsilon_1,...,\epsilon_m\right),
\end{equation}
with positive coordinates is called the \textit{reserve vector} and is used as a parameter in the algorithm.
\item
For each interval $(x_{i-1},x_i)$,$1 \leq i \leq k+1$, calculate the \textit{characteristic} $R(i)$: 
\[
R(i)=\Delta_i+ \frac{(z_i-z_{i-1})^2}{(r_\nu\mu_\nu)^2\Delta_i}-2\frac{z_i+z_{i-1}-2z^\ast_\nu}{r_\nu\mu_\nu},\;\; \nu=\nu(x_{i-1})=\nu(x_i),
\]
\[
R(i)= 2\Delta_i-4\frac{z_i-z^\ast_\nu}{r_\nu\mu_\nu},\;\; \nu(x_{i-1})<\nu(x_i)=\nu,
\]
\[
R(i)= 2\Delta_i-4\frac{z_{i-1}-z^\ast_\nu}{r_\nu\mu_\nu},\;\; \nu = \nu(x_{i-1})>\nu(x_i).
\]
where $\Delta_i=(x_i-x_{i-1})^{1/N}$, and the values $r_\nu>1, 1\leq\nu\leq m+1$, are used as parameters in the algorithm.
\item
Reorder the characteristics $R(i)$, $1\leq i \leq k+1$, from highest to lowest 	
\begin{equation}\label{Eq:23}
R(t_1)\geq R(t_2)\geq ... \geq R(t_{k})\geq R(t_{k+1})
\end{equation}
and choose $p$ largest characteristics with interval numbers $t_j, 1\leq j \leq p$.
\item
Carry out $p$ new trials in parallel at the points $x^{k+j}, 1 \leq j \leq p$, calculated by the formulae
\begin{eqnarray*}
& x^{k+j}=\frac{x_{t_j}+x_{t_j-1}}{2}, \; \nu(x_{t_j-1})\neq \nu(x_{t_j}), \\
& x^{k+j}=\frac{x_{t_j}+x_{t_j-1}}{2}- \frac{\mathrm{sign}(z_{t_j}-z_{t_j-1})}{2r_\nu}\left[\frac{\left|z_{t_j}-z_{t_j-1}\right|}{\mu_\nu}\right]^N, \; \nu(x_{t_j-1})=\nu(x_{t_j})=\nu. \\
\end{eqnarray*} 

\end{enumerate}

The algorithm stops if the condition $\Delta_{t_j}\leq \epsilon$ becomes true for at least one number $t_j, 1\leq j \leq p$; here  $\epsilon>0$ has an order of magnitude of the desired coordinate accuracy.
A detailed description of the algorithm convergence theory is presented in \cite{Strongin2000}.

\section{Parallel algorithm for mixed-integer problems}
%Russian
Рассмотрим теперь случай, когда аргумент функций задачи содержит две компоненты: вектор $y$, принадлежащий гиперинтервалу $D$, и вектор $u$, имеющий конечный (и при этом не очень большой) набор возможных значений, т.е. 
\begin{gather}\label{problem_i}
\min{\left\{ g_{m+1}(y,u):y\in D, \; g_i(y,u)\leq 0, \; 1 \leq i \leq m\right\}},\\
D=\left\{a_j\leq y_j \leq b_j, \; 1\leq j \leq N \right\}.\nonumber
\end{gather}

Такие конечные наборы могут характеризовать, например, вариант материала, из которого создается объект, геометрические размеры или другие величины, которые могут принадлежать стандартному дискретному ряду, и т.п.

Занумеруем целыми числами $s, 1\leq s \leq S,$ все возможные значения вектора $u$, т.е. сопоставим каждому рассматриваемому значению $s$ вектор $u_s$. 
Тогда рассматриваемая задача может быть записана в виде 
\begin{gather}\label{problem_is}
 \min_{s\in\{1,...,S\}}\left(\min{\left\{ g_{m+1}(y,u_s):y\in D, \; g_i(y,u_s)\leq 0, \; 1 \leq i \leq m\right\}}\right),\\
D=\left\{ a_j\leq y_j \leq b_j, \; 1 \leq j\leq N \right\}.\nonumber 
\end{gather}

Используя схему редукции размерности с помощью развертки $y(x), x\in [0,1]$ можно сопоставить каждой вложенной задаче минимизации по $y$ одномерную задачу минимизации
\[
 \min{\left\{ g_{m+1}(y(x),u_s):x \in [0,1], \; g_i(y(x),u_s)\leq 0, \; 1 \leq i \leq m\right\}}, s\in\{1,...,S\}.
\]

Рассмотрим теперь соответствие 
\[
Y(x)=y(x-E(x)), \; x\in[0,S],
\]
отображающее любую точку интервала [0,S] на область $D$ (обозначение $E(x)$ соответствует целой части числа $x$) и определим функции 
\[
g_i(x) = g_i(Y(x),u_{E(x)+1}), x\in[0,S],
\]
имеющие, вообще говоря, разрывы первого рода в целочисленных точках $x_k = i, 1\leq i \leq S-1$.
Значение  $z_k = g_\nu(y(x_k))$ из (\ref{trial_result}) в этих точках будем считать неопределенным, а значения индекса -- равным 0, т.е. $\nu(x_k) = 0$ .

Используя введенные обозначения можно переформулировать исходную задачу как
\begin{equation}\label{problem_is1}
\min \left\{g_{m+1}(x): x \in [0,S], \; g_i(x) \leq 0, \; 1 \leq i \leq m\right\}.
\end{equation}

As an illustration, Fig. \ref{fig:1} presents the plots of the functions corresponding to a 
problem with one continuous parameter and one binary parameter.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth] {fig1.jpg}
    \caption{Reduced mixed-integer global optimization problem}
    \label{fig:1}
\end{figure}

Applying the parallel index algorithm to solving the problem (\ref{problem_is1}), we will find 
the solution of the problem (\ref{problem_i}). In this case the major part of trials will conducted in 
the subproblem, the solving of which corresponds to the solving of the initial 
problem (\ref{problem_i}). In the rest subproblems, a only minor part of trials will be performed 
since the solutions of these subproblems are the locally optimal ones.
%with respect to the solution of the $s$-th subproblem. 
All the above is confirmed by Fig. \ref{fig:1}, where the  
points of trials executed in the course of solving this problem are denoted by the dashes.


Thus, we have constructed the \textit{Mixed-Integer Parallel Index Algorithm} (MIPIA) based on the  
reduction of the mixed-integer non-convex optimization problem to the non-convex optimization problem. 
%Russian
Предложенная схема основана на параллельном индексном методе для решения задач непрерывной оптимизации и не является ориентированной на конкретное вычислительное устройство. Одной из ключевых операций здесь является параллельное проведение нескольких испытаний в различных точках области поиска (см. шаг 7 алгоритма), которе может быть реализовано как на CPU (с использованием OpenMP и/или MPI), так и на GPU (с использованием CUDA). Вопросы использования GPU для этих целей были детально рассмотрены в \cite{Barkalov2016,Gergel2016}, указанный подход к использованию GPU был применен и при реализации алгоритма MIPIA.


\section{Results of experiments}
%Russian
Первая серия экспериментов была проведена с использованием последовательной версии предложенного алгоритма с целью его сравнения с известными методами аналогичного назначения.

Let us compare proposed MIPIA with a genetic algorithm for solving the mixed-integer global optimization problems implemented in Matlab Global Optimization Toolbox \cite{Matlab}. In Table 
\ref{tab:1}, the numbers of trials required for solving the known test mixed-integer 
problems by these methods are presented. For both methods, the same accuracy of search $10^{-2}$ were used. These numerical experiments were conducted on a 
computer with Intel Core i5-7300 2.5 GHz processor and 8 Gb RAM under MS Windows 10. The 
results of experiments have demonstrated the advantage of MIPIA in the number 
of iterations as well as in the execution time.

\begin{table}
	\caption{Comparison of MIPIA and GA}
	\label{tab:1}
	\center
	\begin{tabular}{cccccc}
		\hline\noalign{\smallskip}
	\multirow{2}{*}{Test problem}	 & \multicolumn{2}{c}{ GA } & & \multicolumn{2}{c}{MIGSA} \\
		\noalign{\smallskip} \cline{2-3} \cline{5-6} \noalign{\smallskip}
		 & $k$ & $t$ & & $k$ & $t$  \\
		\noalign{\smallskip} \hline \noalign{\smallskip}
		 Problem 2 \cite{Floudas}&	481 &	0.0601 & &	417 &	0.04 \\
		 Problem 3 \cite{Floudas}& 	1821 &	0.1130 & & 3324 &	0.107 \\
		 Problem 6 \cite{Floudas}&	641 &	0.0510 & &	118 &	0.001 \\
		 Problem 1 \cite{Deep}   &	481 &	0.1378 & &	66 &	0.0007 \\
		 Problem 2 \cite{Deep}   &	481 &	0.0473 & &	57 &	0.0006 \\
		 Problem 7 \cite{Deep}   &	841 &	0.0736 & & 372	 &	0.017 \\
		\noalign{\smallskip}\hline
	\end{tabular}
\end{table}

Последующие серии экспериментов были выполнены для оценки ускорения параллельной версии предложенного алгоритма MIPIA с использованием как CPU, так и GPU. В данных экспериментах решалась серия из 100 тестовых mixed-integer problems, сгенерированных случайных образом.  

Известным генератором тестовых задач непрерывной многоэкстремальной оптимизации является GKLS-генератор \cite{Gaviano}. Он позволяет генерировать functions of arbitrary dimensionality with known properties (the number of local minima, the size of their domains of attraction, the global minimizer, etc.).  
This generator of multiextremal functions is often used for the investigations of the global optimization algorithms~ 
\cite{Paulavicius2014,SergeyevKvasov2015,Lebedev2015,Gergel2015}. 
In Fig.~\ref{example} (a) and (b), the contour plots of two-dimensional GKLS functions are presented. Figures also shows the points of the trials performed by the method until the required accuracy $\epsilon=10^{-2}$ was achieved.

\begin{figure}
\begin{minipage}{0.5\linewidth}
\center{\includegraphics[width=1.0\linewidth]{GKLS-4.png} \\ (a)}
\end{minipage}
\hfill
\begin{minipage}{0.5\linewidth}
\center{\includegraphics[width=1.0\linewidth]{GKLS-6.png} \\ (b)}
\end{minipage}
\caption{Solving a two-dimensional problem using the index algorithm}
\label{example}
\end{figure}

В проведенных экспериментах GKLS-генератор использовался как основа для построения mixed-integer problems. Правила, позволяющие генерировать тестовые задачи подобного вида, заключаются в следующем.

\begin{enumerate}
	\item С помощью генератора GKLS порождается непрерывная многоэкстремальная функция $\varphi(y), \; y\in D, \; D = \left\{ a_j\leq y_j\leq b_j, 1\leq j \leq N \right\}$. Глобальный минимум данной функции достигается в известной точке $y'=(y'_1,...,y'_N)$ и равен $\varphi'=\varphi(y')=-1$.
	\item Генерируется concave mixed-integer function 
	\[
			\mu(y,u) = -2 \left[ \sum_{j=1}^N \left( \frac{y_j - y'_j}{b_j-a_j} \right)^2 + \sum_{j=1}^M \left( \frac{u_j - b_j}{b_j-a_j} \right)^2 \right],
	\]
	где 
	\begin{gather}
	y\in D = \left\{ a_j\leq y_j\leq b_j, 1\leq j \leq N \right\} \subset R^N,\nonumber \\
	u\in U = \left\{ u_j \in  \left\{a_j, ..., b_j \right\}, 1\leq j \leq M \right\};\nonumber
	\end{gather}
	т.е. данная функция имеет $N$ непрерывных и $M$ дискретных параметров и достигает минимального значения в точке $(y',b)$.
	\item Вычисляется коэффициент 
	\[
	C = 4 - \min_{y,u} \left\{ \mu(y,u) \right\}, \; y\in D, u \in U.
	\]
	Очевидно, что минимум вогнутой функции $\mu(y,u)$ в одной из угловых точек области поиска, поэтому при размерности задачи порядка 10 его вычисление может быть выполнено методом перебора.
	\item Формируется многоэкстремальная mixed-integer function 
	\[
	f(y,u) = \left(\varphi(y) + \sum_{j=1}^M{u_j}\right)\left(C + \mu(y,u)\right).
	\]
	По построению $f(y,u)$  будет принимать минимальное значение в точке $(y',b)$.
	
\end{enumerate}


In the problems generated in our experiments, there were 5 discrete and 6 continuous parameters 
	\begin{gather}
	y\in D = \left\{ -1 \leq y_j\leq 1, 1\leq j \leq 6 \right\} \subset R^6,\nonumber \\
	u\in U = \left\{ u_j \in  \left\{-1, -1/3, 0, 1/3, 1 \right\}, 1\leq j \leq 5 \right\}.\nonumber
	\end{gather}

Было сгенерировано 100 11-и мерных mixed-integer problems данного типа. The accuracy of the search was equal to $10^{-2}$.   
Computational experiments were carried out on Lobachevsky supercomputer. The node of 
supercomputer included two Intel Sandy Bridge E5-2660 2.2 GHz CPUs and 64 Gb RAM. The 
CPU had 8 cores, i.e. each node had a total of 16 cores and two NVIDIA Kepler K20Х GPUs.


В Table \ref{tab:2} приведены результаты экспериментов на CPU с использованием OpenMP в зависимости от числа задействованных threads $p$. Использовалось 1, 8 и 16 потоков. Приведено среднее число итераций $K_{av}$, требуемое для решения задачи, среднее время решения $T_{av}$ (в секундах), time speedup $S$ and iteration speedup $s$ (по отношению к последовательному запуску, т.е. $p=1$). В соответствии со схемой распараллеливания число испытаний на одной итерации параллельного алгоритма равнялось числу задействованных threads.

\begin{table}
	\caption{Результаты экспериментов на CPU}
	\label{tab:2}
	\center
	\begin{tabular}{cccccc}
		\hline\noalign{\smallskip}        
		$p$ & $T_{av}$ & $K_{av}$ & $S$ & $s$ \\
	\noalign{\smallskip} \hline \noalign{\smallskip}
	1 \;&	5520 \;  & 3221023 \;  & ...\; & ...  \\
	8 \;&	1253 \; & 512314 \;  & 4.4\; & 6.3  \\
	16\;&  717 \; &  209237 \; & 7.7\; & 15.4 \\
		\noalign{\smallskip}\hline
	\end{tabular}
\end{table}



Как видно из Table \ref{tab:2} , наблюдается почти линейное ускорение по итерациям и значительное ускорение по времени решения задачи, при этом последовательному алгоритму в среднем требовалось примерно 1.5 часа для решения задачи.

В Table \ref{tab:3} приведены результаты экспериментов на GPU с использованием CUDA в зависимости от числа задействованных GPU-threads. Приведено среднее число итераций $K_{av}$, требуемое для решения задачи, среднее время решения $T_{av}$ (в секундах), time speedup $S$ and iteration speedup $s$ (по отношению к полной загрузке CPU на узле кластера). 

\begin{table}
	\caption{Результаты экспериментов на GPU}
	\label{tab:3}
	\center
	\begin{tabular}{cccccc}
		\hline\noalign{\smallskip}
			$p$ & $T_{av}$ & $K_{av}$ & $S$ & $s$ \\
	\noalign{\smallskip} \hline \noalign{\smallskip}
	256 \;&	33.6 \; & 1522\;  & 21.3 \; & 137  \\
	512 \;&	31.2 \; & 919 \;  & 23.0 \; & 228  \\
	1024\;& 30.2 \; & 412 \; & 23.7  \; & 508  \\
	2048\;& 38.5 \; & 244 \; & 18.6  \; & 858  \\
		\noalign{\smallskip}\hline
	\end{tabular}
\end{table}

Результаты эксперимнетов показывают почти одинаковое time speedup и линейное iteration speedup при использовании $p=256, 512, 1024$ threads. Однако при использовании $p=2048$ threads время работы алгоритма замедляется, но число итераций продолжает падать. Данный эффект объясняется тем, что для параллельного проведения $p$ испытаний используется GPU, а для обработки результатов испытаний (которая подразумевает работу со всей накопленной на предыдущих итерациях поисковой информацией) используется CPU. И при использовании $p=2048$ GPU threads время, которое тратится на передачу и обработку результатов 2048 испытаний, становится сопоставимым со временем проведения испытания, что и приводит к замедлению алгоритма в целом.


\section{Conclusion}
%Russian
В данной статье представлены результаты, полученные в Lobachevsky State University of Nizhni Novgorod при разработке и  исследовании параллельных алгоритмов глобальной оптимизации для решения многоэкстремальных задач, в которых часть параметров является непрерывными, а часть - дискретными.
Для задач указанного класса был предложен эффективный параллельный алгоритм их решения алгоритм. 
В последовательном варианте данный алгоритм не уступает алгоритму аналогичного назначения, реализованному в Matlab Global Optimization Toolbox.
В параллельном варианте предложенный алгоритм допускает эффективную реализацию как на CPU, так и на GPU. 
Проведены вычислительные эксперименты на серии из 100 multiextremal mixed-integer problems, убедительно демонстрирующие хорошее ускорение алгоритма с использованием GPU.
Так, параллельный алгоритм с использованием GPU показал time speedup $S = 182$ по отношению к последовательному алгоритму и $S = 23.7$ по отношению к алгоритму, полностью задействующему два CPU на узле кластера.


\begin{thebibliography}{10}

\bibitem{Burer}
Burer, S., Letchford, A.N.: Non-convex mixed-integer nonlinear programming: A survey. Surveys in Operations Research and Management Science \textbf{17}, 97--106 (2012) 

\bibitem{Boukouvala}
Boukouvala, F., Misener, R., Floudas, C.A.: Global optimization advances in Mixed-Integer Nonlinear Programming, MINLP, and Constrained Derivative-Free Optimization, CDFO. European J. Oper. Res. \textbf{252}, 701--727 (2016) 

\bibitem{Deep}
Deep, K., Singh, K. P., Kansal, M.L., Mohan, C.: A real coded genetic algorithm for solving integer and mixed integer optimization problems. Appl. Math. Comput. \textbf{212}(2), 505--518 (2009)

\bibitem{Schluter}
Schl\"uter, M., Egea, J.A., Banga, J.R.: Extended ant colony optimization for non-convex mixed integer nonlinear programming. Computers and Operations Research \textbf{36}(7), 2217--2229 (2009)

\bibitem{Belotti}
Belotti, P., Lee, J., Liberti, L., Margot, F., W\"achter, A.: Branching and bounds tightening techniques for non-convex MINLP. Optim. Method. Softw. \textbf{24}(4-5), 597--634 (2009)

\bibitem{Vigerske}
Vigerske, S., Gleixner, A.: SCIP: global optimization of mixed-integer nonlinear programs in a branch-and-cut framework. 
Optim. Method. Softw. \textbf{33}(3), 563--593 (2018)

\bibitem{Strongin2000}
Strongin, R.G., Sergeyev, Y.D.: Global optimization with non-convex constraints. Sequential and parallel algorithms. Kluwer Academic Publishers, Dordrecht (2000) %; DOI: 10.1007/978-1-4615-4677-1

\bibitem{Strongin2013}
Sergeyev, Ya.D., Strongin, R.G., Lera, D.: Introduction to global optimization exploiting space-filling curves. Springer (2013) %;  DOI: 10.1007/978-1-4614-8042-6

\bibitem{Floudas}
Floudas, C.A., Pardalos, P.M.:  Handbook of test problems in local and global optimization. Springer (1999)  %; DOI: 10.1007/978-1-4757-3040-1

\bibitem{Matlab}
https://www.mathworks.com/help/gads/mixed-integer-optimization.html


\bibitem{Gaviano} Gaviano, M., Kvasov, D.E, Lera, D., and Sergeyev, Ya.D.: Software for generation of classes of test functions with known local and global minima for global optimization. ACM Transactions on Mathematical Software \textbf{29}(4), 469--480 (2003)

\bibitem{Paulavicius2014} 
Paulavi\v{c}ius, R., Sergeyev, Y., Kvasov, D., \v{Z}ilinskas, J.: Globally-biased DISIMPL algorithm for expensive global optimization. J. Glob. Optim. \textbf{59}(2-3), 545--567 (2014)

\bibitem{SergeyevKvasov2015} 
Sergeyev, Y.D., Kvasov, D.E.: A deterministic global optimization using smooth diagonal auxiliary functions. Commun. Nonlinear. Sci. Numer. Simulat. \textbf{21}(1-3), 99--111 (2015)

\bibitem{Lebedev2015}
Lebedev, I., Gergel, V.: Heterogeneous parallel computations for solving global optimization problems. Procedia Computer Science \textbf{66}, 53--62 (2015)

\bibitem{Gergel2015}
Gergel, V., Sidorov, S.: A two-level parallel global search algorithm for solution of computationally intensive multiextremal optimization problems. Lecture Notes in Computer Science  \textbf{9251}, 505--515 (2015)

\bibitem{Barkalov2016} 
Barkalov, K., Gergel, V.: Parallel global optimization on GPU. Journal of Global Optimization 66(1), 2--20 (2016) 

\bibitem{Gergel2016}
Barkalov, K., Gergel, V., Lebedev, I.: Solving Global Optimization Problems on GPU Cluster. In: Simos T.E. (Ed.) ICNAAM 2015, AIP Conference Proceedings, vol. 1738, art. no. 400006 (2016)



\end{thebibliography}


\end{document}
______________________________________________________________________
