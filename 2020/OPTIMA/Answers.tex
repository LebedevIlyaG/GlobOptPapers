%% Based on a TeXnicCenter-Template by Gyorgy SZEIDL.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------------------------------------
%
\documentclass{article}%
%
\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{ulem}
\usepackage{cancel}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel} % Русские и английские переносы

%-------------------------------------------

\begin{document}

\section*{Answers to the reviewers' comments
%for the paper ``Parallel global optimization algorithm with uniform convergence for solving a set of constrained global optimization problems''
}


We thank very much all the reviewers for their useful comments and suggestions.
Please find below our answers that we suggest to clarify the issues.

%\phantom{f}

\subsection*{Answers to Reviewer 1}

\subsubsection*{Major comments}

\begin{enumerate}
\item
First of all, this is the Nizhny Novgorod version of the English demonstrated by the authors. ... I recommend that the authors should seek professional help from experienced translators of mathematical texts.

\textbf{Answer}.
The paper corrected by an English-speaking person.

\item The principal objective of the paper, which is to solve the number (set) of nonconvex problems, is not presented conveniently in the manuscript. There is no mathematical formulation of the problem, say, in the form of an optimization problem, meanwhile the authors tell us about “the optimal way” of solving such a problem, without substantiating this view.

\textbf{Answer}.
Clarification of the objective of this work was added to the end of the Section 2.

\item As well-known now, the solution of (1-3)-dimensional math programming problems, even nonconvex ones, has no considerable difficulties (say, with the help of B\&B methods) and, hence, it is not an attractive value for estimation of the power and effectiveness of algorithms.

\textbf{Answer}.
В рассматриваемых задачах целевая функция и ограничения предполагаются многоэкстремальными и заданными в виде ``черного ящика''. Кроме того, подразумевается, что каждое испытание (т.е. последовательное вычисление значений ограничений и целевой фукнции) является трудоемкой операцией и может потребовать значительных вычислительных ресурсов. Такая постановка часто встречается при решении прикладных задач (например, задач нелинейной аппроксимации; решении систем нелинейных уравнений и неравенств; подборе параметров математических моделей по экспериментальным данным, и т.п.). Поэтому задачи липшицевой глобальной оптимизации даже с одной переменной до сих пор вызывают интерес исследователей [1,2], а задачи размерности 2-3 являются стандартными для тестирования и сравнения алгоритмов липшицевой глобальной оптимизации [3].

В статью добавлен комментарий по поводу сложности задач рассматриваемого класса (see ...), а также численные эксперименты
по решению задач размерности 4 (see Section 4.1 and Table 1).

1. Calvin, J.M., Chen, Y., {\v Z}ilinskas, A. An Adaptive Univariate Global Optimization Algorithm and Its Convergence Rate for Twice Continuously Differentiable Functions. J. Optim. Theory Appl. 155, 628–636 (2012)

2. Sergeyev, Y.D., Mukhametzhanov, M.S., Kvasov, D.E. et al. Derivative-Free Local Tuning and Local Improvement Techniques Embedded in the Univariate Global Optimization. J. Optim. Theory Appl. 171, 186--208 (2016)

3. Paulavi{\v c}ius, R., {\v Z}ilinskas, J. Simplicial Global Optimization. Springer Briefs in Optimization. Springer, New York (2014)


\item There is no comparison of the computational results with popular approaches in the Global Optimization, such as Random Searches, Genetics Algorithms (for example), and other bioinitiated methods.
Additionally, we recommend that the authors pay attention to the DCA methods (by P.D.Tao and L.Th.An) which are able of producing a stationary (KKT-) vector and even a global solution (sometimes) to DC problems.

\textbf{Answer}.
Результаты сравнения core Global Search Algorithm с рядом nature-inspired methods при решении нескольких сотен тестовых задач приведены в [1]. Результаты показывают, что GSA обеспечивает лучшее качество решения задач (решается большее число задач за меньшее число поисковых испытаний). В текст статьи добавлен соответствующий комментарий (see page 11).

Еще раз отметим, что в работе рассматриваются задачи с функциями вида ``черный ящик'' (i.e., an analytical representation of the functions is not available). Поэтому сравнение с методами, использующими аналитическое представление функций задачи (например, основанными на идеях DC-оптимизации, see [2] and references given therein) не будет являться корректным. В текст статьи добавлен соответствующий комментарий (see page 2).

1. Sovrasov, V.  Comparison of Several Stochastic and Deterministic Derivative-Free Global Optimization Algorithms.  Lecture Notes in Computer Science. 11548, 70--81 (2019)

2. Pham Dinh T., Le Thi H.A. Recent Advances in DC Programming and DCA. Lecture Notes in Computer Science. 8342, 1--37 (2014)

\end{enumerate}


\subsubsection*{Minor comments}

\begin{enumerate}
\item p. 3. Apparently, $z_k\neq g_s(x_k ) =:z_{ks}$.
\textbf{Answer}.
This formula was reformulated.

\item  “To account for the latter” change for “On account of”.
\textbf{Answer}.
The phrase was replaced.

\item  p. 4. To put more clear the definition (DF) of $Q_i$ (poor grammar usage).
\textbf{Answer}.
The definition was added to the Section 3. See equation (5).

\item  Delete “At that” (???) globally.
\textbf{Answer}.
Deleted.

\item “At the point” put instead of “in the point”.

\textbf{Answer}.
Fixed.

\item  Specify the DF of the trial (what is it?) at the point $x$.

\textbf{Answer}.
The definition of the trial was clarified. See the description after the equation (6).

\item  Where is a DF of $\nu(x)$?

\textbf{Answer}.
See Section 3, equation (6).

\item  Is it relevant to use at Step 1 “juxtapose”? What does it mean?

\textbf{Answer}.
Here “juxtapose” means combine points and the corresponding results of trials into pairs.
The sentence was clarified.

\item  It seems that in Theorem 1 it is sufficient to assume that $D\neq\emptyset$ (I-st theorem of Weierstrass).

\textbf{Answer}.
The original formulation of the theorem was made for the interval [0,1], this assumption is missing indeed.

\item  Delete “Beginning with some step”, put simply “IF …”

\textbf{Answer}.
Deleted.

\item  Change “admissible” for “feasible”.

\textbf{Answer}.
Done.

\item  The equalities (12) are wrong.

\textbf{Answer}.
The $\inf$ operator is missing here. It was added. See equation (14).

\item  Delete “where $y_*$ is from (3)”.

\textbf{Answer}.
Deleted.

\item  Completely reformulate Theorem 2.

\textbf{Answer}.
The theorem was reformulated using new aliases for algorithms.

\item  Before Table 1 the numbers (?) $p, S_i, S_t$ are not correctly defined.

\textbf{Answer}.
The definitions were added to the Section 4.1.

\item  Delete two last propositions before Table 1.

\textbf{Answer}.

\item  Completely rewrite the conclusion. As it is, it is not written in English.

\textbf{Answer}.
Conclusion was rewritten.

\item  The English and the terminology must be similar to [6] and [16].

\textbf{Answer}.
Definitions and terminology in the Section 3 was corrected.

\end{enumerate}



\subsection*{Answers to Reviewer 2}

\textbf{Comment}. Is it possible to find different solutions by the suggested technique, please, give some comments.

\textbf{Answer}.
The presented method converges to all the global optimal solutions at once, but numerically it's hard
to obtain them all with a guarentee. That happens because of luck of an appropriate stopping criterion.


\subsection*{Answers to Reviewer 3}

\textbf{Comment}. It's not clear why solving a series of global optimization problems in parallel is an important problem. From my experience such problem statement sounds artificial.

\textbf{Answer}.

A serie of global optimization problems can arise from an mixed-integer problem or
after scalarization [1] of an multi-objective problem [2]. In both cases it's needed to
solve all the problems from the serie approximetely with the same quality, because all of
them are equally important. To speedup this process under constrained computational resources,
we can apply parellelism in couple with a resource balancing approach to guarantee equal
quality of solutions in all the problems by the end of the optimization process.

1. Barkalov, K. and I. Lebedev. “Parallel Global Optimization for Non-convex Mixed-Integer Problems.” RuSCDays (2019).

2. Jahn J. Scalarization in Multi Objective Optimization. In: Serafini P. (eds) Mathematics of Multi Objective Optimization. International Centre for Mechanical Sciences (Courses and Lectures), vol 289. Springer, Vienna (1985).

\end{document}
