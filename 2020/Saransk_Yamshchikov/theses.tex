% !!!!!!!!!!!!!!!!!!   ВНИМАНИЕ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
% Заголовки разделов формируются при помощи команд \section{}, \subsection{}, \subsubsection{}
% Не используйте уровень вложенности заголовков больше трех!
% -----------------------------
% Для оформления теорем, лемм, следствий используйте окружения 
% Def     - Определение
% Teor    - Теорема
% Lem     - Лемма
% Predl   - Предложение
% Ass     - Утверждение
% Cor     - Следствие
% Example - Пример
% -----------------------------
% Доказательство теоремы начинается командой \proof и завершается командой \endproof
% -----------------------------
% Литература помещается в окружение biblio.

\documentclass[11pt, oneside, a4paper]{article}
%\usepackage[cp1251]{inputenc} % кодировка
\usepackage[utf8]{inputenc} % кодировка
\usepackage[english, russian]{babel} % Русские и английские переносы
\usepackage{graphicx}          % для включения графических изображений
\usepackage{cite}              % для корректного оформления литературы
\usepackage{enumitem}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtext}


%стилевой пакет
\usepackage{schoolseminar2020}                                


%\renewcommand{\thefootnote}{*}\footnote{Работа выполнена при частичной финансовой поддержке .....}

\begin{document}
% \udk     - универсальный десятичный классификатор
% \msc     - Индекс предметной классификации (Mathematics Subject Classification)
% \title   - название статьи
% \authors - список авторов
\setcounter{page}{1}


\udk{519.853.4}

\title{
Алгоритм глобальной оптимизации с использованием численных оценок производной минимизируемой функции
\footnote{Исследование выполнено при финансовой поддержке РФФИ в рамках научного проекта № 19-07-00242.}
}


\authors{К.А. Баркалов, А.В. Сысоев, И.С. Ямщиков}
\organizations{Нижегородский государственный университет им. Н.И. Лобачевского}


% \section{название} - заголовок раздела первого уровня
% \subsection{название} - заголовок раздела второго уровня
% \subsubsection{название} - заголовок раздела третьего уровня

\bigskip

В работе рассматривается задача поиска глобального минимума $x^*$ одномерной функции $\varphi(x)$ вида
\begin{equation}\label{problem}
\varphi(x^*)=\min\left\{\varphi(x):x\in\left[a,b\right]\right\}.
\end{equation}
Предполагается, что целевая функция является многоэкстремальной и задана в виде ``черного ящика'', т.е. некоторого алгоритма вычисления ее значений. 

В задачах вида (\ref{problem}) получение гарантированных оценок глобального минимума возможно только при наличии тех или иных предположений о поведении минимизируемой функции $\varphi(x)$. Одним из наиболее часто используемых предположений является выполнимость условия Липщица
\[
\left|\varphi(x_1)-\varphi(x_2)\right|\leq L\left|x_1-x_2\right|,\; x_1,x_2 \in [a,b],\; 0<L<\infty.
\]
Условие Липщица соответствует предположению ограниченности изменения значения функции при ограниченном изменении ее аргумента. Данное условие позволяет строить оценки возможного поведения функции $\varphi(x)$ на основе конечного множества ее значений, вычисленных в точках области поиска $[a,b]$.

Более сильным предположением о характере поведения функции является липшицевость ее первой производной 
\begin{equation}\label{LipD}
\left|\varphi'(x_1)-\varphi'(x_2)\right|\leq L_1\left|x_1-x_2\right|,\; x_1,x_2 \in [a,b],\; 0<L_1<\infty.
\end{equation}
Выполнение условия (\ref{LipD}) позволяет формировать более точные оценки возможных значений минимизируемой функции $\varphi(x)$, что обеспечивает возможность существенного повышения эффективности разрабатываемых алгоритмов. 
Однако при решении задач оптимизации с функциями вида ``черный ящик'' точные значения производных, как правило, недоступны, а их численная оценка (с помощью операторов численного дифференцирования) требует дополнительных вычислений значений функции. 
При этом даже одно вычисление значения функции (\textit{испытание}) является трудоемкой операцией, т.к. связано с проведением численного моделирования.   

Следовательно, перспективной является разработка методов глобальной оптимизации, в которых необходимые значения производных вычисляются на основе точек предшествующих итераций, без проведения дополнительных поисковых испытаний.  


%Предполагается также, что целевая функция является многоэкстремальной и задана в виде ``черного ящика'', т.е. некоторого алгоритма вычисления значения функции и ее производной в зависимости от параметра. При этом каждое \textit{испытание} (т.е. вычисление значений $\varphi(x)$ и $\varphi'(x)$ в точке $x$) является трудоемкой операцией, т.к. связано  с необходимостью численного моделирования.  


В работе \cite{Gergel96} был сформулирован алгоритм глобального поиска с использованием производных для решения одномерных задач. 
Данный метод в процессе своей работы предполагает построение последовательности точек $x^k\in[a,b]$, в которых проводятся испытания. Множество троек $ \{ x^i, \varphi^i=\varphi (x^i), \varphi'^i=\varphi'(x^i)\}, 0 \leq i \leq k,$ составляет поисковую информацию, накопленную методом после проведения $k$ шагов. 

Общая схема алгоритма может быть представлена в следующем виде. Первые два испытания проводятся в граничных точках области поиска, т.е. $x^0 = a, x^1 = b$. Для выбора точки $x^{k+1}, k>1,$ очередного испытания требуется выполнить следующие действия.

\begin{enumerate}
	\item Перенумеровать точки $x^0,...,x^k$ предшествующих испытаний нижним индексом в порядке возрастания координаты, т.е.
	\begin{equation}\label{order}
		a=x_0<x_1<...<x_k=b,
	\end{equation}
	и сопоставить им значения $ \varphi_i=\varphi (x_i), \varphi'_i=\varphi'(x_i)\}, 0 \leq i \leq k,$ вычисленные в этих точках.
	\item Для каждого интервала $(x_{i-1},x_i), 1\leq i\leq k$, вычислить его \textit{характеристику} $R(i)$.
	\item Определить интервал с максимальной характеристикой 
	\[
	R(t)=\max\{R(i), 1\leq i \leq k\}.
	\]
	\item Провести следующее испытание в точке интервала с максимальной характеристикой, т.е. $x^{k+1}\in(x_{t-1},x_t).$
	\item Проверить условие остановки $x_t-x_{t-1}<\epsilon$, где $t$ -- номер интервала с максимальной характеристикой, а $\epsilon > 0$ -- заданная точность. 
	\end{enumerate}
	
	Конкретные формулы для вычисления характеристики интервала и точки проведения нового испытания, а также соответствующие теоретические утверждения о сходимости алгоритма представлены в \cite{Gergel96}.


В рамках проведенного исследования был предложен алгоритм, в котором точные значения производных заменяются их численными оценками, вычисленными на основе ранее накопленной поисковой информации. 
В соответствии с нумерацией (\ref{order}) точек испытаний в порядке возрастания координаты в качестве численных оценок значений производных $\overline{\varphi_i}' = \overline{\varphi}'(x_i) \approx \varphi'(x_i)$, $0\leq i\leq k$ можно использовать трехточечную аппроксимацию вида
\[
\overline{\varphi_0}' = \frac{1}{H_1}\left(-(2+\delta_{2})\varphi(x_{0}) + \frac{(\delta_{2}+1)^2}{\delta_{2}}\varphi(x_1) - \frac{1}{\delta_{2}}\varphi(x_{2}) \right),
\]
\begin{equation}\label{numer}
\overline{\varphi_i}' = \frac{1}{H_i}\left(-\delta_{i+1}\varphi(x_{i-1}) - \frac{\delta_{i+1}^2-1}{\delta_{i+1}}\varphi(x_i) + \frac{1}{\delta_{i+1}}\varphi(x_{i+1}) \right), \; 0<i<k,
\end{equation}
\[
\overline{\varphi_k}' = \frac{1}{H_{k-1}}\left(\delta_{k}\varphi(x_{k-2}) - \frac{(\delta_{k}+1)^2}{\delta_{k}}\varphi(x_{k-1}) + \frac{2+\delta_k}{\delta_{k}}\varphi(x_k) \right),
\]
где $H_i=h_i+h_{i+1}$, $\delta_{i+1}=\frac{h_{i+1}}{h_i}$, $h_i=x_i-x_{i-1}$.

Таким образом, новый алгоритм представляет собой дальнейшее развитие метода из \cite{Gergel96}, в котором значения первой производной минимизируемой функции заменяются их численные оценками вида (\ref{numer}). Отметим, что в алгоритме вместо априори неизвестного значения константы Липшица $L_1$ для $\varphi'(x)$ используется ее адаптивная оценка $m$, вычисляемая на основе полученной поисковой информации. 
Справедлива следующая теорема о сходимости алгоритма.
\begin{Teor} Пусть $\{x^k\}$ есть последовательность точек испытаний, порождаемой алгоритмом при минимизации  функции $\varphi(x), x\in[a,b],$ производная которой удовлетворяет условию Липщица с константой $L_1$, и пусть на некотором шаге поиска $k$ для адаптивной оценки константы Липшица $m$ справедливо неравенство 
\[
rm>\gamma L_1, \; \gamma = \left[ 4(b-a) + (b-a)^2 +0.5 \right]/\epsilon^2 ,
\]
где $r>1$ -- параметр, а $\epsilon>0$ -- точность в условии остановки алгоритма.
Тогда любая точка глобального минимума $x^*$ является предельной точкой последовательности $\{x^k\}$ и, кроме того, любая предельная точка $\overline{x}$ этой последовательности является точкой глобального минимума функции $\varphi(x)$.
\end{Teor}

Для демонстрации эффективности предложенного алгоритма глобального поиска с использованием численных оценок производных (АГПЧП)  было проведено сравнение со следующими методами глобальной оптимизации: метод Гальперина (МГ) \cite{Galperin}, метод Пиявского (МП) \cite{Pijavski72}, алгоритм глобального поиска Стронгина (АГП) \cite{Strongin2013}, алгоритм глобального поиска с использованием производных (АГПП) \cite{Gergel96}. Сравнение было проведено при решении серии из 20 многоэкстремальных задач, использованных для оценки эффективности методов глобальной оптимизации в \cite{Gergel96}.

В проведенных экспериментах точность поиска решения составила $\epsilon=10^{-4}(b-a)$, где $a$ и $b$ -- границы области поиска. Для методов Гальперина и Пиявского использовались точные значения константы Липшица минимизируемой функции, оцененные предварительно. Для алгоритма глобального поиска Стронгина использовалось значение параметра $r=2$. Для методов с использованием производных использовался параметр $r=1.1$. В таблице 1 отражено среднее число итераций (округленное до целых значений), потребовавшихся методам для решения всех задач серии. 

\begin{table}[h]
	\caption{Результаты решения серии задач}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			& МГ & МП & АГП & АГПП & АГПЧП \\
			\hline
			\hline
			Среднее число итераций & 720 & 314 & 244 & 26 & 24  \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

Результаты экспериментов наглядно демонстрируют превосходство (по числу итераций) методов с использованием производных над методами, в которых производные не используются. Одновременно с этим видно, что методам АГПП и АГПЧП требуется примерно одинаковое число итераций. При этом каждая итерация АГПП подразумевает вычисление точного значения производной, тогда как в АГПЧП никакие дополнительные вычисления значений функции и ее производных не требуются.

Направлением дальнейших исследований будет являться исследование свойств предложенного алгоритма при решении многомерных задач многоэкстремальной оптимизации. Обобщение на многомерные задачи может быть выполнено, например, с использованием схемы диагонального разбиения области поиска \cite{Sergeyev2008} или же с использованием схемы рекурсивной (вложенной) оптимизации \cite{Grishagin2007}.


\begin{biblio}



%\bibitem{Evtushenko2009} Евтушенко Ю.Г., Малкова В.У., Станевичюс А.-И.А. Параллельный поиск глобального экстремума функций многих переменных // Ж. вычисл. матем. и матем. физ. 2009. Т. 49, № 2.  С. 255--269.

%\bibitem{Elsakov} Елсаков С.М., Ширяев В.И. Однородные алгоритмы многоэкстремальной оптимизации // Ж. вычисл. матем. и матем. физ. 2010. Т. 50, № 10. С. 1727--1740.

\bibitem{Gergel96}
Гергель В.П. Об одном способе учета значений производных при минимизации многоэкстремальных функций // Ж. вычисл. матем. и матем. физ. 1996. Т. 36, №5. С. 51--67.

\bibitem{Galperin}
Galperin E.A. The cubic algorithm // J. Math. Anal. Appl. 1985. Vol. 112. P. 635--640.

\bibitem{Pijavski72}
Пиявский С.А. Один алгоритм отыскания абсолютного экстремума функций // Журн. вычисл. матем. и матем. физ. 1972. Т. 12. № 4. С. 888--896.

\bibitem{Strongin2013}
Стронгин Р.Г., Гергель В.П., Гришагин В.А., Баркалов К.А. Параллельные вычисления в задачах глобальной оптимизации. М.: Изд-во МГУ, 2013. 280 с.

\bibitem{Sergeyev2008} Сергеев Я.Д., Квасов Д.Е. Диагональные методы глобальной оптимизации. М.: Физматлит, 2008. 352 с. 

\bibitem{Grishagin2007} Городецкий~С.Ю., Гришагин~В.А. Нелинейное программирование и многоэкстремальная оптимизация. Н.~Новгород: Изд-во ННГУ, 2007. 489~с.


%\bibitem{Gergel97} Gergel V.P. A global optimization algorithm for multivariate function with Lipschitzian first derivatives // J. Glob. Optim. 1997. Vol. 10(3). P. 257--281.


\end{biblio}

\msc{90C26}

\title{Global optimization algorithm using numerical estimates of the objective function derivative}

\authors{K.A. Barkalov, A.V. Sysoyev, I.S. Yamshchikov}
\organizations{ Lobachevsky State University of Nizhni Novgorod }



\end{document}

