%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[entropy,article,submit,moreauthors,pdftex]{Definitions/mdpi} 

% For posting an early version of this manuscript as a preprint, you may use "preprints" as the journal and change "submit" to "accept". The document class line would be, e.g., \documentclass[preprints,article,accept,moreauthors,pdftex]{mdpi}. This is especially recommended for submission to arXiv, where line numbers should be removed before posting. For preprints.org, the editorial staff will make this change immediately prior to posting.

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% acoustics, actuators, addictions, admsci, adolescents, aerospace, agriculture, agriengineering, agronomy, ai, algorithms, allergies, analytica, animals, antibiotics, antibodies, antioxidants, appliedchem, applmech, applmicrobiol, applnano, applsci, arts, asi, atmosphere, atoms, audiolres, automation, axioms, batteries, bdcc, behavsci, beverages, biochem, bioengineering, biologics, biology, biomechanics, biomedicines, biomedinformatics, biomimetics, biomolecules, biophysica, biosensors, biotech, birds, bloods, brainsci, buildings, businesses, cancers, carbon, cardiogenetics, catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, chemproc, children, civileng, cleantechnol, climate, clinpract, clockssleep, cmd, coatings, colloids, compounds, computation, computers, condensedmatter, conservation, constrmater, cosmetics, crops, cryptography, crystals, curroncol, cyber, dairy, data, dentistry, dermato, dermatopathology, designs, diabetology, diagnostics, digital, disabilities, diseases, diversity, dna, drones, dynamics, earth, ebj, ecologies, econometrics, economies, education, ejihpe, electricity, electrochem, electronicmat, electronics, encyclopedia, endocrines, energies, eng, engproc, entropy, environments, environsciproc, epidemiologia, epigenomes, fermentation, fibers, fire, fishes, fluids, foods, forecasting, forensicsci, forests, fractalfract, fuels, futureinternet, futuretransp, futurepharmacol, futurephys, galaxies, games, gases, gastroent, gastrointestdisord, gels, genealogy, genes, geographies, geohazards, geomatics, geosciences, geotechnics, geriatrics, hazardousmatters, healthcare, hearts, hemato, heritage, highthroughput, histories, horticulturae, humanities, hydrogen, hydrology, hygiene, idr, ijerph, ijfs, ijgi, ijms, ijns, ijtm, ijtpp, immuno, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jcdd, jcm, jcp, jcs, jdb, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmp, jmse, jne, jnt, jof, joitmc, jor, journalmedia, jox, jpm, jrfm, jsan, jtaer, jzbg, kidney, land, languages, laws, life, liquids, literature, livers, logistics, lubricants, machines, macromol, magnetism, magnetochemistry, make, marinedrugs, materials, materproc, mathematics, mca, measurements, medicina, medicines, medsci, membranes, metabolites, metals, metrology, micro, microarrays, microbiolres, micromachines, microorganisms, minerals, mining, modelling, molbank, molecules, mps, mti, nanoenergyadv, nanomanufacturing, nanomaterials, ncrna, network, neuroglia, neurolint, neurosci, nitrogen, notspecified, nri, nursrep, nutrients, obesities, oceans, ohbm, onco, oncopathology, optics, oral, organics, osteology, oxygen, parasites, parasitologia, particles, pathogens, pathophysiology, pediatrrep, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photochem, photonics, physchem, physics, physiolsci, plants, plasma, pollutants, polymers, polysaccharides, proceedings, processes, prosthesis, proteomes, psych, psychiatryint, publications, quantumrep, quaternary, qubs, radiation, reactions, recycling, regeneration, religions, remotesensing, reports, reprodmed, resources, risks, robotics, safety, sci, scipharm, sensors, separations, sexes, signals, sinusitis, smartcities, sna, societies, socsci, soilsystems, solids, sports, standards, stats, stresses, surfaces, surgeries, suschem, sustainability, symmetry, systems, taxonomy, technologies, telecom, textiles, thermo, tourismhosp, toxics, toxins, transplantology, traumas, tropicalmed, universe, urbansci, uro, vaccines, vehicles, vetsci, vibration, viruses, vision, water, wevj, women, world 

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, book, bookreview, briefreport, casereport, comment, commentary, communication, conferenceproceedings, correction, conferencereport, entry, expressionofconcern, extendedabstract, datadescriptor, editorial, essay, erratum, hypothesis, interestingimage, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, studyprotocol, systematicreview, supfile, technicalnote, viewpoint, guidelines, registeredreport, tutorial
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figures are used, remove the option pdftex and use LaTeX and dvi2pdf.

%%%% ДЛЯ РУССКОГО ТЕКСТА закомментировать потом!
%\usepackage{inputenc}
%\usepackage[T2A,T1]{fontenc}
%\usepackage[english,russian]{babel}
%\usepackage{cmap}
%%%%


%=================================================================
% MDPI internal commands
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2021}
\copyrightyear{2020}
%\externaleditor{Academic Editor: Firstname Lastname} % For journal Automation, please change Academic Editor to "Communicated by"
\datereceived{} 
\dateaccepted{} 
\datepublished{} 
\hreflink{https://doi.org/} % If needed use \linebreak
%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, soul, multirow, microtype, tikz, totcount, changepage, paracol, attrib, upgreek, cleveref, amsthm, hyphenat, natbib, hyperref, footmisc, url, geometry, newfloat, caption

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Acceleration of Global Optimization Algorithm by Detecting Local Extrema Based on Machine Learning}
		   %Acceleration of Global Optimization Algorithm by Detecting Local Extrema Based on Machine Learning

% MDPI internal command: Title for citation in the left column
\TitleCitation{}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0001-5273-2471} % Add \orcidA{} behind the author's name
\newcommand{\orcidauthorB}{0000-0002-8736-0652} % Add \orcidB{} behind the author's name
\newcommand{\orcidauthorC}{0000-0001-6776-0096} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Konstantin Barkalov $^{1}$*\orcidA{} , Ilya Lebedev $^{1}$\orcidB{} and Evgeny Kozinov $^{1}$\orcidC{}}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Konstantin Barkalov, Ilya Lebedev and Evgeny Kozinov}

% MDPI internal command: Authors, for citation in the left column
\AuthorCitation{Barkalov, K.; Lebedev, I.; Kozinov, E.}
% If this is a Chicago style journal: Lastname, Firstname, Firstname Lastname, and Firstname Lastname.

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address[1]{%
$^{1}$ \quad Department of Mathematical Software and Supercomputing Technologies, Lobachevsky University, 603950 Nizhny Novgorod, Russia; ilya.lebedev@itmm.unn.ru (I.L.), evgeny.kozinov@itmm.unn.ru (E.K.)}
%$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: konstantin.barkalov@itmm.unn.ru (K.B.)}
%; Tel.: (optional; include country code; if there are multiple corresponding authors, add author initials) +xx-xxxx-xxx-xxxx (F.L.)}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation 3} 
%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{
The paper features the study of global optimization problems and numerical methods of their solution. Such problems are computationally expensive since the objective function can be multi-extremal, nondifferentiable, and, as a rule, given in the form of a ``black box''. The study used a deterministic algorithm for finding the global extremum. The said algorithm is based neither on the concept of multistart, nor nature-inspired algorithms. The article provides computational rules of the one-dimensional algorithm and the nested optimization scheme which could be applied for solving multidimensional problems. Note that the solution complexity of global optimization problems essentially depends on the presence of multiple local extrema. In this paper, we apply machine learning methods to identify regions of attraction of local minima. The use of local optimization algorithms in the selected regions can significantly accelerate the convergence of global search as it could reduce the number of search trials in the vicinity of local minima. The results of computational experiments carried out on several hundred global optimization problems of different dimensionalities presented in the paper confirm the effect of accelerated convergence (in terms of the number of search trials required to solve a problem with a given accuracy).
}

% Keywords
\keyword{global optimization; local optimization; multiextremal problems; numerical methods; approximation; decision trees} 

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences:
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:
%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Encyclopedia
%\encyclopediadef{Instead of the abstract}
%\entrylink{The Link to this entry published on the encyclopedia platform.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

%The introduction should briefly place the study in a broad context and highlight why it is important. It should define the purpose of the work and its significance. The current state of the research field should be reviewed carefully and key publications cited. Please highlight controversial and diverging hypotheses when necessary. Finally, briefly mention the main aim of the work and highlight the principal conclusions. As far as possible, please keep the introduction comprehensible to scientists outside your particular field of research. Citing a journal paper \cite{ref-journal}. Now citing a book reference \cite{ref-book1,ref-book2} or other reference types \cite{ref-unpublish,ref-communication,ref-proceeding}. Please use the command \citep{ref-thesis,ref-url} for the following MDPI journals, which use author--date citation: Administrative Sciences, Arts, Econometrics, Economies, Genealogy, Histories, Humanities, IJFS, Journal of Intelligence, Journalism and Media, JRFM, Languages, Laws, Religions, Risks, Social Sciences.

The successful application of machine learning (ML) methods to solve a wide range of problems leads to the emergence of new ways to apply ML for many tasks. 
Methods of machine learning were shown to be particularly effective for identifying the principal properties of the phenomena (for example, physical, economic, or social), which are stochastic by nature or contain some hidden parameters \cite{Golovenkin2020,Gonoskov2019}.
ML is also successfully used to solve complex problems of computational mathematics, for example, for simulation of dynamical systems  \cite{Seleznev2019}, solution of ordinary, partial, or stochastic differential equations \cite{Lagaris1998,Blechschmidt2021,Xu2020}.

Particularly, ML could be applied for solving such a complex problem of computational mathematics as global optimization.
The solution to this class of problems, as a rule, cannot be found analytically and, therefore, one needs to construct numerical methods to solve it.

The numerical solution of optimization problems is fraught with significant difficulties. In many ways, they are related to the dimensionality and type of the objective function. Consequently, the most difficult problems are those in which the objective function is multi-extremal, nondifferentiable, and, moreover, given in the form of a ``black box'' (i.e., in the form of some computational procedure, the input of which is an argument, and the output is the corresponding value of the function). These complex problems are the main focus of this article.

There are several approaches to the construction of numerical methods for solving global optimization problems. 
Some algorithms are based on the idea of a multistart: launching a local search either from different starting points or with varying parameters. Local optimization methods have a high convergence rate. At the same time, one of the main problems in multistart schemes is the choice of starting points that would correspond to the regions of attraction of various local solutions. 
Machine learning methods can be successfully applied to solve this problem.  
For example, in \cite{RinnooyKan1987} methods of cluster analysis were used to select promising starting points.
In \cite{Cassioli2012} the area for starting the local method was allocated based on the classification of starting points using a support vector machine.

%Russian
{ \color{red}
Machine learning methods are actively used in combination with bayesian optimization algorithms based on the probabilistic surrogate models of the objective function. The detailed overview of this trend in the development of global optimization methods is presented in \cite{Archetti2019,Zhigljavsky2021}.
}

Another popular class of methods for solving global optimization problems is metaheuristic algorithms. 
Many of them are based on imitation of the processes occurring in living nature. The parameters of such algorithms could also be tuned using ML. For example, \cite{Jin2005} provides an overview of machine learning applications in evolutionary algorithms.

Note that the algorithms of the latter class do not provide guaranteed convergence to the solution of the problem and are inferior to deterministic algorithms in terms of the quality of solution \cite{Kvasov2018,Sergeyev2018} (e.g., measured by the number of correctly solved problems from a particular set). Therefore, deterministic methods seem to be potentially more effective.

%Russian
This paper aims to further develop the efficient deterministic global optimization method known as \textit{the information-statistical global search algorithm} \cite{Strongin2000}. The book referenced here contains the results of theoretical studies of the method that are of direct importance for its practical implementation. In particular, it discusses in detail the issues of convergence, the choice of parameters, and the conditions for stopping the algorithm, etc.
Note that the global search algorithm was originally designed for solving unconstrained optimization problems. Later, it was generalized to solve problems with non-convex constraints\cite{Barkalov2002} and multicriteria optimization problems \cite{Gergel2020}.
At the same time, scholars proposed various parallel versions of these algorithms, which can be used on modern supercomputers \cite{Barkalov2016,globalizerSystem,Strongin2018}.


Several strategies have been proposed to speedup the global search algorithm (in terms of the number of iterations required to solve the problem with a given accuracy). In this paper, we propose a new approach to acceleration based on identifying areas of attraction of local minima using machine learning methods. The identification of regions of attraction and the launch of local search in these regions can significantly reduce the number of trials required for the method to achieve global convergence. Experiments carried out on a series of several hundred test problems confirm this statement. 



\section{Problem Statement}

In this paper, we will consider global optimization problems of the form
\begin{eqnarray}\label{main_problem}
& \varphi(y^\ast)=\min{\left\{\varphi(y):y\in D\right\}},\\
& D=\left\{y\in \text{R}^N: a_i\leq y_i \leq b_i, 1\leq i \leq N\right\}. \nonumber
\end{eqnarray}
Problem (\ref{main_problem}) is considered under the assumption that the objective function is multi-extremal, is given in a form of a ``black box'', and the calculation of its values is associated with solving the problem of numerical simulation, which makes the solution a labor-intensive operation.

A typical situation for many applied problems is when a limited change in the vector of parameters $y$ causes a limited change in the values of $\varphi(y)$. The mathematical model describing this premise is based on the assumption that the Lipschitz condition is satisfied
\[
\left|\varphi(y')-\varphi(y'')\right|\leq L\left\|y'-y''\right\|,\; y',y'' \in D,\; 0<L<\infty.
\]
This assumption is typical for many approaches to the development of optimization algorithms \cite{Jones1993,Pinter1996,Zilinskas2008,Evtushenko2009,Sergeyev2020}.
At the same time, many known approaches are based on various methods of dividing the search domain into a system of subdomains and then choosing the most promising subdomain for placing the next trial (calculating the value of the objective function)  \cite{Jones2009,Zilinskas2010,Evtushenko2013,Kvasov2013,Paulavicius2016,Paulavicius2020}. 
An important property of global optimization problems is the fact that, in contrast to the problems of finding a local extremum, the global minimum is an integral characteristic of the problem being solved. Making sure that the point  $y^*\in D$ is a solution to the problem requires going beyond its neighborhood to the investigation of the entire search domain. As a result, when minimizing substantially multi-extremal functions, the numerical method must construct a coverage of the search domain. The number of nodes of this coverage increases exponentially with increasing dimensionality. 
This feature determines the high complexity of solving multiextremal optimization problems making dimensionality a critical factor that affects the complexity of their solving.

The dimensionality in multi-extremal optimization leads to many issues, so, scholars use a wide variety of approaches to reducing it.  
For example, simplicial or diagonal partition of the search domain allows using methods for solving one-dimensional problems to solve the original multidimensional problem (see, for example,  \cite{PaulaviciusZilinskas2014,Sergeyev2017}). 
Another well-known approach to dimensionality reduction is using the Peano space-filling curves to map the multidimensional domain onto a one-dimensional interval \cite{Strongin2000,Sergeyev2013}.

In this work, we will use another method based on the nested optimization scheme \cite{Shi2000,Grishagin2001,VanDam2010,Grishagin2015} and its generalization \cite{Grishagin2016,Grishagin2016_1}.
The nested optimization scheme, on the one hand, does not worsen the properties of the objective function (unlike reduction using Peano curves), and, on the other hand, does not require the use of complex data structures to support simplex or diagonal partitions of the feasible region.
At the same time, the nested optimization scheme makes it possible to reduce the original multidimensional optimization problem to a family of recursively connected one-dimensional optimization subproblems, which can be solved by a wide range of one-dimensional global optimization algorithms.


\section{Methods}

\subsection{Core global search algorithm}\label{CoreGSA}

As a standard, let us consider a one-dimensional multiextremal optimization problem
\begin{equation}\label{uni_problem}
\varphi^\ast = \varphi(x^\ast)=\min{\left\{\varphi(x):x\in \left[a,b\right], a<b, a,b \in R
\right\}}
\end{equation}
with an objective function satisfying the Lipschitz condition. 

Here is the description of global search algorithm (GSA) for solving the basic problem in accordance with \cite{Strongin2000}.
In the course of its work, GSA generates a sequence of points  $x^i$, at which the values of the objective function  $z^i=\varphi(x^i)$ are calculated. 
We will refer to the process of calculating the value of the objective function as \textit{trial}.

In accordance with the algorithm, the first two trials are carried out at the boundary points of the segment $[a,b]$, i.e. $x^0=a,\;x^1=b$. 
At these points, the values of the objective function  $z^0=\varphi(x^0),\;z^1=\varphi(x^1)$ are calculated and the counter value is set to $k=1$. 
The point of the next trial $x^{k+1}, k\geq 1,$ is selected in accordance with the following procedure.

 Step 1. Renumber  (starting at 0) the points $x^i,\:0\leq i\leq k$, of the trials conducted  in ascending order of the coordinate, i.e.
\begin{equation}\label{xt}
a=x_0<x_1<\ldots <x_{k}=b.
\end{equation} 
Associate the values of the objective function $z_i=\varphi(x_i), \; 0\leq i\leq k,$ to the points $x_i, \; 0\leq i\leq k$, at which these values were calculated.

Step 2. Calculate the maximum absolute value of the relative first difference
\begin{equation}\label{mu}
\mu=\max_{1\leq i\leq k}\frac{\left|z_i-z_{i-1}\right|}{\Delta_i},
\end{equation}
where $\Delta_i = x_i-x_{i-1}$. If the value calculated in accordance with (\ref{mu}) is equal to zero, then take $\mu = 1$.

Step 3. For all the intervals $(x_{i-1},x_i),1\leq i\leq k$,  calculate the value
\begin{equation}\label{R}
R(i)=r\mu\Delta_i+\frac{(z_i-z_{i-1})^2}{r\mu\Delta_i}-2(z_i+z_{i-1}),
\end{equation} 
refered to as the \textit{characteristics} of the interval; value $r>1$ is the parameter of the algorithm. 

Step 4. Find the interval $(x_{t-1},x_t)$ with the maximum characteristic
\begin{equation}\label{MaxR}
R(t)=\max_{1\leq i\leq {k}}R(i).
\end{equation}
If the maximum characteristic corresponds to several intervals, then choose the minimum number that satisfies (\ref{MaxR}) as $t$.

Step 5. Carry out a new trial at the point
\begin{equation}\label{xk1}
x^{k+1}=\frac{1}{2}(x_{t-1}+x_t) - \frac{z_t-z_{t-1}}{2r\mu}.
\end{equation}

The algorithm stops when the condition  $\Delta_t<\epsilon$ is satisfied; here $t$ is from (\ref{MaxR}), and $\epsilon>0$ is a given accuracy. 
The values
\[
z_k^\ast=\min_{0\leq i \leq k}\varphi(x^i), \ x_k^\ast=\arg \min_{0\leq i \leq
 k}\varphi(x^i)
\] 
are selected to estimate the solution

The theoretical conditions that determine the convergence of the algorithm are presented in \cite{Strongin2000}. 
The work of the algorithm during the minimization of a specific multiextremal function, which is specified in accordance with formula  (\ref{hill}), is shown in Figure \ref{fig1}. The algorithm was launched with the parameter $r=2.2$ from (\ref{R}) and value $\epsilon = 10^{-3}$ in the method stopping condition.
Figure \ref{fig1} shows the objective function graph and points of 71 search trials which GSA needed to solve the problem to the specified accuracy. This highlights the problem of all methods of global optimization --- the concentration of trial points in the vicinity of local minima of the problem, which are not a global solution.

\begin{figure}[H]
\includegraphics[width=1.0\linewidth]{HillAGP90.png}
\caption{Minimization of a function of the form  (\ref{hill}) using GSA.}
\label{fig1}
\end{figure}   


\subsection{Machine Learning Regression as a tool for identifying attraction regions of local extrema}\label{TreeGSA}

The functions considered in this study belong to the class of Lipschitzian functions. Therefore, classical regression methods (for example, polynomial regression, where a function is approximated by a polynomial of a given degree) will not properly match the behavior of the function.
A more powerful tool for this task is regression splines. When constructing a regression spline, the domain is divided into $K$ non-overlapping subdomains. In each of such domains, the function is approximated by a polynomial. Dividing the interval into a sufficient number of subdomains allows one to very accurately approximate the original function.

Regression can also be constructed using such a powerful tool as artificial neural networks. 
Different types of networks can be used to build the regression, for example, multilayer perceptron, radial basis function network, etc.
However, in both of these cases, the model itself (spline or neural network) becomes rather complex for the analysis required to solve the given problem (identifying areas of attraction of local extrema).

Therefore, within the framework of the study, we chose a regression model based on decision trees to analyze the local behavior of a function.
For example, if the objective function is properly approximated by polynomials, then the polynomial regression, of course, will appropriately convey the properties of the function. However, if there is a more complex relationship between them, then the decision tree can surpass the classical variants of regression in terms of the quality of the approximation. 
At the same time, the regression based on the decision tree makes it possible to easily identify the areas of attraction of local extrema with sufficient accuracy.

Building a regression using a decision tree consists of two main steps:
\begin{itemize}
	\item Search domain $D$ is divided into $J$ non-overlapping subdomains  $D_1, D_2, ..., D_J$, provided that $D = \bigcup_{j=1}^{J}{D_j}$.
	\item Any value falling into the subdomain $D_j$, i.e. $x \in D_j$, is matched to the average value  $c_j$ based on the training trials that fall into this subdomain. 
\end{itemize}
In fact, decision trees build a model of a function of the form
\begin{equation}\label{dtree}
f(x) = c_j, \; x\in D_j.
\end{equation}

%Russian
{\color{red}
Generally speaking, a decision tree is a binary tree, the leave nodes of which contain the values of the function, and the other nodes contain the transition conditions.
In our case, when applying a decision tree to construct a regression, each node corresponds to the results of several trials and the value $c_j$, which is calculated as the mean square of the trial points assigned to this node.
The final piecewise constant approximation is constructed using the values $c_j$, located in the leave nodes of the tree. 

The tree is built recursively, starting from the root node. 
A decision rule is applied at each node: all data is divided into two groups (according to a partitioning rule) and sent to the left and right child nodes. The procedure then recursively separates the left and right nodes. 
Recursion stops at a node in one of the following cases:
\begin{itemize}
	\item The number of trial points assigned to the node becomes less than the specified threshold value (we used 1).
	\item The sum of the squared deviations of the function values from the value $c_j$, assigned to this node becomes less than the set accuracy (we used $10^{-3}$).
\end{itemize}
For more information on the algorithm for constructing regression using decision trees, see, for example \cite{Breiman1984}.
}

Regression built using decision trees,
is, on the one hand, rather simple, and on the other hand, it adequately reflects the properties of the function under investigation (the presence or absence of local minima). The selection of regions of attraction of local minima using model (\ref{dtree}) can be organized as follows.

Let $x^{k+1}$ be the point of the current trial. For a given point, an index  $j$ is sought such that $x^{k+1} \in D_j$. 
Next, the  $c_j$ values corresponding to neighboring subdomains are compared. If one of the conditions is met
\begin{gather}
c_{j} \leq c_{j+1} \leq c_{j+2} \leq c_{j+3} \leq c_{j+4}, \; j=1; \nonumber \\ 
c_{j-1} \geq c_{j} \leq c_{j+1} \leq c_{j+2} \leq c_{j+3}, \; j=2;  \nonumber \\  
c_{j-2} \geq c_{j-1} \geq c_{j} \leq c_{j+1} \leq c_{j+2}, \; 3 \leq j \leq J-2; \label{LPC} \\ 
c_{j-3} \geq c_{j-2} \geq c_{j-1} \geq c_{j} \leq c_{j+1}, \; j=J-1; \nonumber \\ 
c_{j-4} \geq c_{j-3} \geq c_{j-2} \geq c_{j-1} \geq c_{j}, \; j=J; \nonumber 
\end{gather}
then the subdomain $D_j$ is considered the area of attraction of the local minimum. Here, one can start a local search, and subsequently exclude this subdomain from the global search. 
Any of the zero-order local methods can be used as a local algorithm, for example, golden section search or parabolic interpolation \cite{Press}.

In order to modify the global search algorithm from subsection  \ref{CoreGSA} to exclude the regions of attraction of local minima, we associate each trial point  $x^i$ obtained during the operation of the algorithm with an additional attribute $q^i \in \{0,1,2\}$, which will characterize the properties of this point. 
The value  $q^i=0$ is assigned by default and indicates that point $x^i$ is obtained as a result of rule (\ref{xk1}) of the global search algorithm.
The value $q^i=1$ is assigned to the points obtained as a result of the work of the local method, while the value  $q^i=2$ corresponds to the point of the local minimum found as a result of the work of the local search.

%Russian
{\color{red}
Using the additional attribute $q^i, \; 0 \leq i \leq k ,$ makes it possible to distinguish between points obtained during a global ($q^i=0$) and a local ($q^i=1,2$) search. The intervals, the boundary points of which have the value  $q^i=1$ or $q^i=2$, will be skipped in the global search, i.e. they will not be tried further. 
While the selected value $q^i=2$, which corresponds to the local minimum will allow using these points for checking the stopping criterion. When the rules of the global search signal that a new trial point needs be placed in a given  $\epsilon$-neighborhood of one of the found local minima, this will correspond to the end of the search.
}

Let us now describe a modified global search algorithm that uses decision trees to isolate and exclude areas of attraction of local minima; we will further refer to this algorithm as GSA-DT. Recall that the superscript corresponds to the number of the iteration at which the trial was carried out at this point, and the subscript corresponds to the number of the point in the row  (\ref{xt}).

Steps 1-5 of the GSA-DT algorithm are the same as steps 1-5 of GSA.

Step 6. If $q_{t-1} \in \{1,2\}$ or $q_t \in \{1,2\}$, then go to check the stopping criterion. Otherwise, go to Step 7.

Step 7. Construct a decision tree based on the results of the trials performed, and obtain the corresponding piecewise constant approximation, which assigns the value $c_1, c_2, ..., c_J$ to each subdomain  $D_1, D_2, ..., D_J$.

Step 8. For the point $x^{k+1}$ of the current trial, find a number $j$ such that $x^{k+1} \in D_j$ and check whether the condition  (\ref{LPC}) is satisfied. If condition (\ref{LPC}) is satisfied, start a local search in the domain $D_j$ from the point  $x^{k+1}$. 
The results of all trials performed during the local search at the points $x^{k+2}, ...,x^{k+k_{local}}$ are stored in the information base of the algorithm and are used at subsequent iterations. 
All these points receive the attribute  $q^i=1$, $i = k+2, ... , k+k_{local}$. The attribute equal to 2 is assigned to the point corresponding to the found local minimum.

The stopping criterion of the modified algorithm will look as follows. 
The algorithm stops when one of the following conditions is met:

\begin{itemize}
	\item $|x_{t} - x_{t-1}|<\epsilon$;
	\item $|x^{k+1} - x_{t-1}|<\epsilon$ and $q_{t-1} = 2$;
	\item $|x^{k+1}-x_{t}|<\epsilon$ and $q_{t} = 2$;
\end{itemize}
where $t$ is from (\ref{MaxR}), and $\epsilon>0$ is a given accuracy.

%Russian
{\color{red}
Note that the specified stopping criterion is checked after Step 6, i.e. after the calculation according to the rules of the global search for the point of the next trial $x^{k+1}$, but before the trial itself is carried out in it. The idea behind this criterion is as follows. The search stops when the interval  $(x_{t-1},x_t)$, in which the point $x^{k+1}$ falls, becomes sufficiently small, or when the point $x^{k+1}$ falls into a small neighborhood of one of the found local minima. Such minima in this case will be simultaneously global.
}

For example, consider the work of the GSA-DT algorithm with minimization of the same multi-extremal function, which is presented in Figure \ref{fig1}. The same parameters were used at the start of the algorithm: the parameter  $r=2.2$ from (\ref{R}) and value $\epsilon = 10^{-3}$ in the stopping criterion of the method. 
Figure \ref{fig2} illustrates the operation of the GSA-DT algorithm. In addition to the graph of the objective function, it shows a piecewise constant approximation of the form (\ref{dtree}) built at the final stage of the search. Black points on the graph correspond to the global search phase, green points correspond to the work of the local method. In total, the GSA-DT method required 49 trials to solve the problem; there was no accumulation of trial points in the vicinity of local minima.
 
\begin{figure}[H]
\includegraphics[width=1.0\linewidth]{HillTree90.png}
\caption{Using GSA-DT to minimize the function (\ref{hill}) }
\label{fig2}
\end{figure}   


\subsection{Adaptive Dimension Reduction Scheme}

The recursive nested optimization scheme is based on the well-known relation  \cite{Grishagin2001} 
\begin{equation}\label{nested}
\min_{y \in D}\varphi(y) = \min_{y_1\in\left[a_1,b_1\right]}\min_{y_2\in\left[a_2,b_2\right]}...\min_{y_N\in\left[a_N,b_N\right]}\varphi(y),
\end{equation}
which allows reducing the solution of the original multidimensional problem (\ref{main_problem}) to the solution of a family of recursively connected one-dimensional subproblems.

For a formal description of the nested optimization scheme, we introduce a family of functions defined in accordance with the relations
\begin{equation}\label{nested_N}
\varphi_N(y_1,...,y_N) \equiv \varphi(y_1,...,y_N),
\end{equation}
\begin{equation}\label{nested_i}
\varphi_i(y_1,...,y_i) = \min_{ y_{i+1} \in\left[a_{i+1},b_{i+1}\right]} \varphi_{i+1}(y_1,...,y_i,y_{i+1}), 1\leq i\leq N-1.
\end{equation}

Then, in accordance with  (\ref{nested}), solving the multidimensional problem  (\ref{main_problem}) is reduced to solving a one-dimensional problem 
\begin{equation}\label{nested_1}
\varphi^* = \min_{y_1\in\left[a_1,b_1\right]}\varphi_1(y_1).
\end{equation}
However, each calculation of the value of the function $\varphi_1$ at some fixed point $y_1$ presupposes the solution of the one-dimensional optimization problem of the second level
\begin{equation}
\varphi_1(y_1) = \min_{y_2\in\left[a_2,b_2\right]}\varphi_2(y_1,y_2).
\end{equation}
Calculation of the values of the function  $\varphi_2$ in turn, requires one-dimensional minimization of the function  $\varphi_3$ all the way to the solution of the problem
\begin{equation}
\varphi_{N-1}(y_1,...,y_{N-1}) = \min_{ y_{N} \in\left[a_{N},b_{N}\right]} \varphi_{N}(y_1,...,y_{N})
\end{equation}
at the last level of recursion.

The solution of the set of subproblems arising in the nested optimization scheme  (\ref{nested_i}) can be organized in different ways. 
The obvious way (described in detail in \cite{Grishagin2001,Grishagin2015}) is based on solving subproblems in accordance with the recursive order of their generation. However, a significant part of the information about the objective function is lost here.

Another approach is an adaptive scheme, in which all subtasks are solved simultaneously, which allows taking into account much more information about a multidimensional problem, thereby speeding up the process of its solution. 
This approach was theoretically substantiated and tested in  \cite{Grishagin2016,Grishagin2016_1,Grishagin2018}. 

Note that within the framework of the original nested optimization scheme, the generated subproblems are solved only sequentially; the resulting hierarchical scheme for generating and solving subproblems has the form of a tree. The construction of this tree occurs dynamically in the process of solving the original problem (\ref{main_problem}). In this case, the calculation of one value of the function $\varphi_i(y_1,y_2,...,y_i)$ at the $i$-th level requires a complete solution of all problems of one of the subtrees of level  $i+1$.

The adaptive nested optimization scheme of dimensionality reduction changes the order of solving subproblems: they will be solved not one by one (in accordance with their hierarchy in the problem tree), but simultaneously, i.e. there will be a set of subtasks in the process of solution. Within the adaptive scheme:
\begin{itemize}
	\item 
to calculate the value of $i$-th level function from (\ref{nested_i}) a new $i+1$ level problem is generated, in which only one trial is carried out, after which the new generated problem is included in the set of already existing problems to be solved;
	\item 
	iteration of the global search consists in choosing one (most promising) problem from the set of available problems, in which one trial is carried out; the new trial point is determined according to the basic global search algorithm from subsection \ref{CoreGSA} or a modified algorithm from subsection  \ref{TreeGSA};
	\item
the minimum values of functions from  (\ref{nested_i}) are their current estimates obtained based on accumulated search information.
\end{itemize}

%A brief description of the main steps of the adaptive dimensionality reduction scheme is as follows.
%Let nested subproblems of the form (\ref{nested_i}) be solved using the global search algorithm described in subsection  \ref{CoreGSA}. Then each subproblem  (\ref{nested_i})  can be assigned some numerical value called a characteristic of this problem. As such a characteristic, we can take the value $R(t)$ from (\ref{MaxR}), i.e. the maximum characteristic from the characteristics of the intervals formed in this task. The higher the values of this characteristic, the more promising is the search for the global minimum of the original problem (\ref{main_problem}) in the given subproblem.Therefore, at each iteration, a subproblem with the maximum characteristic is selected, and a trial is carried out in it. This either leads to the calculation of the value of the objective function  $\varphi(y)$ (if the selected subtask belonged to the level  $j=M$), or generates new subproblems according to (\ref{nested_i}) for $j\leq M-1$. In the latter case, new generated tasks are added to the current set of tasks, their characteristics are calculated, and the process is repeated. The completion of the optimization process occurs when the condition for stopping the algorithm that solves this problem is satisfied for the root problem.



\section{Experimental Results}

Numerical experiments were performed on the Lobachevsky supercomputer of the University of Nizhny Novgorod (operating system CentOS 7.2, management system SLURM). One supercomputer node has 2 Intel Sandy Bridge E5-2660 2.2 GHz processors, 64 Gb RAM. The CPU is 8-core (i.e. a total of 16 CPU cores are available on the node). All the algorithms were implemented in C++; GCC 5.5.0 was used for compilation on the supercomputer.

The traditional approach to assessing the effectiveness of global optimization methods is based on using these methods to find the numerical solution of a series of problems. 
In this case, the assumption is that a certain algorithm is used to generate the next problem to be solved. 
Typical examples of such test function classes are Shekel and Hill functions. 
The first of them (denoted $F_{SH}$) is based on the formula
\begin{equation}\label{shekel}
  \varphi(x)=-\sum_{j=1}^{10}\frac{1}{(K_j(x-A_j)^2+C_j)},\;  x\in[0,10],
\end{equation}
where parameters $1\le K_j\le 3,\: 0 < A_j,\: C_j < 10, \;$ are independent random variables uniformly distributed in the indicated intervals. 
The next generator (denoted   $F_{HL}$) is determined by the expression
\begin{equation}\label{hill}
  \varphi(x)=\sum_{j=1}^{14}(A_j\sin(2j\pi x) + B_j\cos(2j\pi x)),\: x\in[0,1],
\end{equation}
where the values of the parameters $A_j,\: B_j,\: 1 \le j \le 14$, are independently and uniformly distributed in the interval  $[-1,1]$. 

Let us compare the basic global search algorithm (GSA) and its decision tree-based modification (GSA-DT) with the well-known DIRECT global optimization algorithm  \cite{Jones2009}.
{\color{red}
%Russian 
The choice of this particular method for comparison is explained as follows. DIRECT is one of the most well-known and popular deterministic methods for solving global optimization problems with a `` black box '' objective function. An overview of various modifications of the method, as well as examples of solving problems, is given in \cite{Jones2021}.
It is known that with a sufficiently large number of search trials, DIRECT is guaranteed to find a global solution to the problem. 
However, if the stopping by accuracy is used as a criterion, then the method can abruptly stop at one of the local minima, which is confirmed by the experimental results presented in this section. 

Regarding the deterministic optimization algorithms implemented in popular Computer Algebra Systems (CAS), their comparison with methods such as DIRECT or GSA will be incorrect for the following reason.
Optimization algorithms from CAS are focused on solving problems with an objective function set explicitly, in the form of a formula.
Formula definition of the objective function assumes that its derivatives are also known, which makes it possible to use first-order methods with significantly faster convergence than zero-order methods, which include both DIRECT and GSA. However, first-order methods do not guarantee finding the global minimum. 
For example, the Mathematica system offers methods for solving global optimization problems that are guaranteed to find a global solution to the problem only if the objective function and constraints are linear or convex. Otherwise, the result may sometimes only be a local minimum.

Moreover, methods that require a formulaic specification of the objective function cannot be applied to the solution of a large class of applied problems in which the form of the objective function is not known, and its values are calculated as a result of numerical simulation. The use of heuristic methods for solving problems of this kind (such as Differential Evolution, Simulated Annealing or Random Search) also does not always lead to the solution of the problem. 
These methods often do find the global minimum, but are not guaranteed to do so. In terms of the number of correctly solved problems, heuristic methods are inferior to deterministic ones \cite{Sergeyev2018}.
}

The decision trees in the GSA-DT algorithm were built using the OpenCV 4.5.1 library (class cv::ml::DTrees). A regression function was constructed by a single decision tree. This allowed us to obtain a piecewise constant approximation of the objective function in which one or several trial points corresponded to each leaf node of the tree. 
The tree was built without any limitations on maximum depth (MaxDepth); the accuracy of tree construction (RegressionAccuracy) was $10^{-3}$; the minimum number of trial points in the tree node (MinSampleCount) was equal to one; all other parameters were set by default. Stopping tree building occurred if all absolute differences between an estimated value in a node and values of train samples in this node are less than accuracy.

The global optimization methods discussed above were compared when solving 100 problems from the  $F_{SH}$ and $F_{HL}$ classes. The problem will be considered correctly solved if after stopping the method by accuracy (i.e. when the length of the current search interval becomes less than $\epsilon \cdot \left|b-a\right| $) the current estimate of the optimum  $x_k^*$ lies in the $\epsilon$-neighborhood of the known solution of the problem  $x^*$, i.e. if the condition  $|x^*-x_k^*| \leq \epsilon \cdot \left|b-a\right|$ is satisfied.

Tables \ref{table:average_Shekel} and \ref{table:average_Hill} show the number of search trials that, on average, were required to minimize the Shekel and Hill functions with different search accuracy  $\epsilon$. The number of unsolved problems is indicated in parentheses. 
{\color{red}
These and subsequent tables feature the total number of trials that were performed during both global and local searches by GSA-DT.
When solving problems with an accuracy  $10^{-2}$, $10^{-3}$, $10^{-4}$ the number of local search launches when solving one problem on average was equal to 2, 3, and 4, respectively; and the ratio of the number of trials performed according to the global search rules to the number of trials performed by the local method was (with appropriate accuracy) 7.2, 6.0, 4.5 for problems of the $F_{HL}$ class and 3.2, 2.3, 1.9 for the $F_{SH}$ class problems.
}

%Ebglish
The experimental results show that with a rough solution to the problem, all methods show similar results in terms of the number of trials, while with a high solution accuracy, the GSA-DT algorithm requires 2 times fewer trials than its prototype. At the same time, GSA-DT outperforms the DIRECT method both in the average number of search trials and in the number of correctly solved problems. In particular, if we use the accuracy $\epsilon = 10^{-2}\left|b-a\right|$, then the DIRECT method stops too early and does not find a global solution to many problems. 
Therefore, in further experiments in which multidimensional problems are solved, we will not use DIRECT for comparison, since when solving multidimensional problems with stopping by accuracy, this method will provide a correct solution to no more than  $50\%$ of problems.


\begin{specialtable}[H] 
	\caption{The average number of tests when minimizing Shekel test functions (the number of unsolved problems is indicated in parentheses)}\label{table:average_Shekel}
	\center
\begin{tabular}{cccc}
\toprule
        & \textbf{$\epsilon = 10^{-4}$} & \textbf{$\epsilon = 10^{-3}$} & \textbf{$\epsilon = 10^{-2}$} \\
\midrule													
DIRECT         & 64(1) &  34(6)   & 20(17)    \\
GSA            & 106  & 53  &  31   \\ 
GSA-DT         & 49   & 43  &  35   \\

\bottomrule
\end{tabular}
\end{specialtable}

\begin{specialtable}[H] 
	\caption{The average number of tests when minimizing Hill test functions (the number of unsolved problems is indicated in parentheses))}\label{table:average_Hill}
	\center
\begin{tabular}{cccc}
\toprule
        & \textbf{$\epsilon = 10^{-4}$} & \textbf{$\epsilon = 10^{-3}$} & \textbf{$\epsilon = 10^{-2}$} \\
\midrule					  
DIRECT                & 66(12) & 36(31)  & 20(51)  \\
GSA                   & 130    & 75      & 43      \\
GSA-DT                & 64     & 59      & 50      \\
\bottomrule
\end{tabular}
\end{specialtable}

The next series of experiments involved the solution of multidimensional problems. 
A well-known generator of multi-extremal optimization test problems is GLKS  \cite{Gaviano2003}. It can be used to generate test functions with given properties: the number of local extrema, their areas of attraction, the global minimum point, and the value of the objective function at this point, etc. The procedure for generating test functions is based on using polynomials to redefine a convex quadratic function (paraboloid). Test functions are defined by five parameters:
\begin{itemize}
	\item dimensionality of the problem  $N$;
	\item the number of local minima $l$;
	\item value of the global minimum $f^*$;
	\item radius of the area of attraction of the global optimizer $\rho^*$;
	\item the distance between the global optimizer and the vertex of the paraboloid $d^*$.
\end{itemize}
By changing the specified parameters, one can create test classes with different properties. For example, with a fixed dimensionality of the problem and the number of local minima, a more complex class can be generated by narrowing the region of attraction of the point of the global minimum or by increasing the distance between this point and the vertex of the paraboloid. 
In the experiments, the values $l=10$, $f^*=-1$, $\rho^*=0.2$ and $d^*=0.9$ were used.


As an example, consider the operation of the GSA and GSA-DT algorithms when solving one of the two-dimensional problems generated by the GKLS generator. 
The level lines of the objective function shown in Figures \ref{fig3} and \ref{fig4}, indicate the presence of ten local extrema. 
When starting the algorithms, the same parameters were used:  $r=3.0$ from (\ref{R}) and $\epsilon = 10^{-2}\left|b-a\right|$ in the stopping criterion of the method. 
Black dots in Figures \ref{fig3} and \ref{fig4} show the points of the search trials performed by the methods in the process of solving the problem. In this case, the GSA algorithm required 247 trials, while the GSA-DT algorithm took 138 trials.
The red dot in the figures marks the exact solution of the problem, and the yellow dot indicates the best approximation found by the algorithm. 
Green dots in Figure \ref{fig4} indicate trials performed as part of a local search. 
This graph demonstrates that using decision trees to identify areas of attraction of local minima removes the problem of accumulation of test points in the region of local extrema inherent in the original global search algorithm.


\begin{figure}[H]
\includegraphics[width=0.6\linewidth]{GKLSAdaptiv6_30line.png}
\caption{Using GSA algorithm to solve GKLS problems}
\label{fig3}
\end{figure}   

\begin{figure}[H]
\includegraphics[width=0.6\linewidth]{GKLSTree6_30line.png}
\caption{Using GSA-DT algorithm to solve GKLS problems}
\label{fig4}
\end{figure}   

We used GKLS to generate 300 test problems of dimensionalities $N=2,3,4$ (100 problems of each dimensionality).
The resulting series of problems were solved using the GSA and GSA-DT algorithms with the parameter $r=5.0$ from (\ref{R}). The specified value of the parameter $r$ ensures the solution of  $100\%$ of the problems; at lower values of the parameter, some problems were not solved correctly.

Tables \ref{table:average_GKLS01} and \ref{table:average_GKLS002} show the average number of trials required by the GSA and GSA-DT methods to correctly solve all problems with an accuracy of $\epsilon = 10^{-2}\left|b-a\right|$ and $\epsilon = 2 \cdot 10^{-3}\left|b-a\right|$ respectively.

The data from the tables confirm that the global search algorithm based on the application of machine learning to extract local extremum provides a faster solution to multiextremum problems than the basic global search algorithm. For rough accuracy solutions, the acceleration is about  $30\%$, for high accuracy solutions, the process is accelerated from 2 to 6 times.

\begin{specialtable}[H] 
	\caption{Solving GKLS problems with an accuracy  $\epsilon = 10^{-2}\left|b-a\right|$}\label{table:average_GKLS01}
	\center
\begin{tabular}{cccc}
\toprule
        & $N=2$ & $N=3$  & $N=4$    \\
\midrule
GSA     &  937  &  12716 &  206869  \\
GSA-DT  &  653  &  9204  &  156190  \\
\bottomrule
\end{tabular}
\end{specialtable}

\begin{specialtable}[H] 
	\caption{Solving GKLS problems with an accuracy $\epsilon = 2 \cdot 10^{-3}\left|b-a\right|$}\label{table:average_GKLS002}
	\center
\begin{tabular}{cccc}
\toprule

       & $N=2$ & $N=3$  & $N=4$    \\
\midrule
GSA    & 1489  & 69764  & 583903  \\
GSA-DT & 831   & 10776  & 173155   \\
\bottomrule
\end{tabular}
\end{specialtable}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work}

The article discusses an efficient deterministic method for solving multiextremal optimization problems --- the information-statistical global search algorithm.
A new way of speeding up the operation of this algorithm was proposed (in terms of the number of trials required to solve the problem with a given accuracy). This method is based on identifying areas of attraction of local minima of the objective function using machine learning methods. The identification of regions of attraction and the launch of local search in these regions can significantly reduce the number of trials required for the method to achieve global convergence. 
Within the framework of the investigated approach, solving multidimensional problems is reduced to solving a series of information-related one-dimensional subproblems; therefore, the key point is to identify local minima in one-dimensional problems. This is achieved by approximation of the objective function built using decision trees. 
Computational experiments were carried out on a series of test problems of different dimensions to compare the speed of the original global search algorithm (GSA) and its modification, which uses decision trees to identify local minima of the objective function (GSA-DT). 
The experimental results show that the use of the GSA-DT algorithm can significantly (up to 6 times) reduce the number of trials required to solve the problem with a given accuracy.

Further research into this issue will focus on using more complex models of the objective function to obtain a more accurate approximation. We plan to use artificial neural networks as such an approximator. This will require the development of new methods for identifying local extrema since function approximation using a neural network is more complicated from this point of view. We also plan to pay attention to the issues of the reliability of the results obtained using machine learning methods. For the solved model problems, the use of machine learning methods shows good results, but the question of whether this effect will persist in more complex problems remains open.

%Russian
{\color{red}
Another direction for further work will be the combination of the proposed approach to the application of local search with traditional methods of accelerating global optimization algorithms. For example, a well-known way to speed up algorithms of this class is to use local adaptive estimates of the Lipschitz constant $L_i$ in various subdomains $D_i \in D$ within the search domain $D$ instead of a single global estimate of the constant $L$ for the entire domain $D$ ( see \cite{Kvasov2020,Sergeyev2021}).
This allows the algorithm to adjust to the local behavior of the objective function in different parts of the feasible domain, and, thereby, reduces the number of search trials required to achieve convergence. Using only global information about the behavior of the objective function during its minimization can significantly slow down the convergence of the algorithm to a point of global minimum. 
Further research on this issue could focus on using machine learning methods to isolate subdomains $D_i \in D$ and construct local estimates of the Lipschitz constant  $L_i$ in the selected subdomains.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Patents}

%This section is not mandatory, but may be added if there are patents resulting from the work reported in this manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\supplementary{The following are available online at \linksupplementary{s1}, Figure S1: title, Table S1: title, Video S1: title.}

% Only for the journal Methods and Protocols:
% If you wish to submit a video article, please do so with any other supplementary material.
% \supplementary{The following are available at \linksupplementary{s1}, Figure S1: title, Table S1: title, Video S1: title. A supporting video article is available at doi: link.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{Conceptualization and methodology, K.B.; software and validation, I.L., E.K.; formal analysis, K.B.; investigation, I.L.; data curation, I.L.; writing --- original draft preparation, K.B.; writing- -- review and editing, K.B.; visualization, I.L.; funding acquisition, K.B. All authors have read and agreed to the published version of the manuscript.}

\funding{This research was funded by the Ministry of Science and Higher Education of the Russian Federation, agreement number 075-15-2020-808.}

\institutionalreview{Not applicable.}

\informedconsent{Not applicable.}

%\dataavailability{In this section, please provide details regarding where data supporting reported results can be found, including links to publicly archived datasets analyzed or generated during the study. Please refer to suggested Data Availability Statements in section ``MDPI Research Data Policies'' at \url{https://www.mdpi.com/ethics}. You might choose to exclude this statement if the study did not report any data.} 

%\acknowledgments{In this section you can acknowledge any support given which is not covered by the author contribution or funding sections. This may include administrative and technical support, or donations in kind (e.g., materials used for experiments).}

\conflictsofinterest{The authors declare no conflict of interest.} 

%% Optional
%\sampleavailability{Samples of the compounds ... are available from the authors.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Only for journal Encyclopedia
%\entrylink{The Link to this entry published on the encyclopedia platform.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional
%\abbreviations{Abbreviations}{
%The following abbreviations are used in this manuscript:\\
%
%\noindent 
%\begin{tabular}{@{}ll}
%MDPI & Multidisciplinary Digital Publishing Institute\\
%DOAJ & Directory of open access journals\\
%TLA & Three letter acronym\\
%LD & Linear dichroism
%\end{tabular}}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Optional
%\appendixtitles{no} % Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
%\appendixstart
%\appendix
%\section{}
%\subsection{}
%The appendix is an optional section that can contain details and data supplemental to the main text---for example, explanations of experimental details that would disrupt the flow of the main text but nonetheless remain crucial to understanding and reproducing the research shown; figures of replicates for experiments of which representative data are shown in the main text can be added here if brief, or as Supplementary Data. Mathematical proofs of results not central to the paper can be added as an appendix.
%
%\begin{specialtable}[H] 
%%\tablesize{\scriptsize}
%\caption{This is a table caption. Tables should be placed in the main text near to the first time they are~cited.\label{tab2}}
%%\tablesize{} % You can specify the fontsize here, e.g., \tablesize{\footnotesize}. If commented out \small will be used.
%\begin{tabular}{ccc}
%\toprule
%\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}\\
%\midrule
%Entry 1		& Data			& Data\\
%Entry 2		& Data			& Data\\
%\bottomrule
%\end{tabular}
%\end{specialtable}
%
%\section{}
%All appendix sections must be cited in the main text. In the appendices, Figures, Tables, etc. should be labeled, starting with ``A''---e.g., Figure A1, Figure A2, etc. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{paracol}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\reftitle{References}

% Please provide either the correct journal abbreviation (e.g. according to the “List of Title Word Abbreviations” http://www.issn.org/services/online-services/access-to-the-ltwa/) or the full name of the journal.
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 

%=====================================
% References, variant A: external bibliography
%=====================================
\externalbibliography{yes}
\bibliography{bibliography}

%=====================================
% References, variant B: internal bibliography
%=====================================
%\begin{thebibliography}{999}
%% Reference 1
%\bibitem[Author1(year)]{ref-journal}
%Author~1, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142--149.
%% Reference 2
%\bibitem[Author2(year)]{ref-book1}
%Author~2, L. The title of the cited contribution. In {\em The Book Title}; Editor1, F., Editor2, A., Eds.; Publishing House: City, Country, 2007; pp. 32--58.
%% Reference 3
%\bibitem[Author3(year)]{ref-book2}
%Author 1, A.; Author 2, B. \textit{Book Title}, 3rd ed.; Publisher: Publisher Location, Country, 2008; pp. 154--196.
%% Reference 4
%\bibitem[Author4(year)]{ref-unpublish}
%Author 1, A.B.; Author 2, C. Title of Unpublished Work. \textit{Abbreviated Journal Name} stage of publication (under review; accepted; in~press).
%% Reference 5
%\bibitem[Author5(year)]{ref-communication}
%Author 1, A.B. (University, City, State, Country); Author 2, C. (Institute, City, State, Country). Personal communication, 2012.
%% Reference 6
%\bibitem[Author6(year)]{ref-proceeding}
%Author 1, A.B.; Author 2, C.D.; Author 3, E.F. Title of Presentation. In Title of the Collected Work (if available), Proceedings of the Name of the Conference, Location of Conference, Country, Date of Conference; Editor 1, Editor 2, Eds. (if available); Publisher: City, Country, Year (if available); Abstract Number (optional), Pagination (optional).
%% Reference 7
%\bibitem[Author7(year)]{ref-thesis}
%Author 1, A.B. Title of Thesis. Level of Thesis, Degree-Granting University, Location of University, Date of Completion.
%% Reference 8
%\bibitem[Author8(year)]{ref-url}
%Title of Site. Available online: URL (accessed on Day Month Year).
%\end{thebibliography}

% If authors have biography, please use the format below
%\section*{Short Biography of Authors}
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author1.pdf}}}
%{\textbf{Firstname Lastname} Biography of first author}
%
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author2.jpg}}}
%{\textbf{Firstname Lastname} Biography of second author}

% The following MDPI journals use author-date citation: Arts, Econometrics, Economies, Genealogy, Humanities, IJFS, JRFM, Laws, Religions, Risks, Social Sciences. For those journals, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

