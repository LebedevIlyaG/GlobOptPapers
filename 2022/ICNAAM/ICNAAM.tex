\documentclass{aip-cp}


\usepackage[numbers]{natbib}
\usepackage{rotating}
\usepackage{graphicx}

%% ДЛЯ РУССКОГО ТЕКСТА закомментировать потом!
\usepackage{inputenc}
\usepackage[T2A,T1]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{cmap}
%%


% Document starts
\begin{document}

% Title portion
\title{Использование методов машинного обучения для разделения параметров в задачах глобальной оптимизации большой размерности}

\author[aff1]{Konstantin Barkalov\corref{cor1}}
\author[aff1]{Marina Usova}

\affil[aff1]{Lobachevsky State University of Nizhny Novgorod, Nizhny Novgorod, Russia}
\corresp[cor1]{Corresponding author: konstantin.barkalov@itmm.unn.ru}

\maketitle

\begin{abstract}
The paper presents results ...
\end{abstract}

% Head 1
\section{INTRODUCTION}

В настоящее время методы глобальной оптимизации используются для решения широкого круга задач, возникающих в различных областях науки и техники. 
Например, традиционной сферой применения методов глобальной оптимизации является идентификация значений параметров математических моделей по данным экспериментов. К их числу относятся, например, inverse problems of chemical kinetics.  В задачах такого вида требуется провести поиск значений неизвестных параметров модели, при которых результаты моделирования наиболее близки к результатам, полученным экспериментально.

Число параметров, которые требуется идентифицировать подобным образом, для задач химической кинетики может составлять десятки и сотни. Использование детерминированных методов глобальной оптимизации для решения задачах такой размерности крайне ограничено из-за чрезвычайно больших вычислительных затрат на покрытие search domain точками испытаний. Это остается справедливым даже в случае использования эффективных алгоритмов (например, \cite{Paulavicius2011,Evtushenko2009,Jones2009}), строящих существенно неравномерные покрытия. 

Многие обратные задачи характеризуются тем, что зависимость от разных групп параметров носит разный характер. Например, от одной группы параметров зависимость может быть близка к линейной, тогда как по второй группе зависимость может носить сложный многоэкстремальный характер.

В этом случае решение задачи можно организовать по схеме recursive optimization. Решение  многоэкстремальной подзадачи, для которой требуется использовать сложные алгоритмы глобальной оптимизации, будет проводиться на верхнем уровне рекурсии.
Унимодальные подзадачи (каждая из которых соответствует фиксированному набору значений первой части параметров) будут решаться на нижнем уровне. Для их решения можно применять обладающие быстрой сходимостью методы локальной оптимизации.

Однако заранее указать разделение на группы параметров с разным характером поведения целевой функции, как правило, не представляется возможным, т.к. целевая функция в обратных задачах задается как черный ящик. 
Таким образом, актуальной является разработка алгоритмов минимизации существенно многомерных функций, в которых учитывается разный характер зависимости целевой функции от разных групп параметров. 
В данной работе предложен конкретный механизм такого разделения, основанный на <указать>.
В качестве примеров, подтверждающих работоспособность предложенной схемы, решены как тестовые, так и прикладные задачи.

\section{ОПТИМИЗАЦИОННЫЕ АЛГОРИТМЫ И РЕДУКИЦЯ РАЗМЕРНОСТИ}

Рассмотрим задачу оптимизации вида
\begin{eqnarray}\label{main_problem}
& \varphi(y^\ast)=\min{\left\{\varphi(y): y\in D\right\}}, \nonumber \\
& D=\left\{y\in R^N: a_i\leq y_i \leq b_i, 1\leq i \leq N\right\}. \nonumber
\end{eqnarray}
Будем предполагать, что функция $\varphi(y)$ является многоэкстремальной и удовлетворяет Lipschitz condition
\[
\left|\varphi(y')-\varphi(y'')\right|\leq L\left\|y'-y''\right\|,\; y',y'' \in D,\; 0<L<\infty,
\]
with the constant $L$ unknown a priori.
Одновременно с этим будет предполагать, что зависимость целевой функции от $N_1$ параметров является многоэкстремальной, а от оставшихся $N_2 = N - N_1$ параметров зависимость являеся близкой к линейной. При этом разделение  параметров является неизвестным. Такой характер зависимостей является типичным, например, для обратных задач химической кинетики [ссылка]. В данной работе предлагается подход к разделению параметров задачи на указанные две группы, конкретный механизм описан в следуюем разделе. 

Учет подобной особенности задач может существенно снизить вычислительную сложность поиска оптимума. В самом деле, в соответствии с известной схемой рекурсивной оптимизации \cite{Carr} решение исходной задачи можно проводить следующим образом:
\begin{equation}\label{global_problem}
\varphi(y^*) = \min_{y\in D} \varphi (y) = \min_{y^1\in D_1} f(y^1), \; D_1=\left\{y\in R^{N_1}: a_i\leq y_i \leq b_i, \; 1\leq i \leq N_1\right\},
\end{equation}
где 
\begin{equation}\label{local_problem}
f(y^1) = \min_{ y^2 \in D_2} \varphi(y^1,y^2), \; D_2=\left\{y\in R^{N_2}: a_i\leq y_i \leq b_i, \; N_1+1\leq i \leq N\right\}.
\end{equation}
В соответствии с (\ref{global_problem}) вычисление одного значения функции $\varphi^1 (y^1)$ (данный процесс будем называть search trial) подразумевает решение унимодальной задачи (\ref{local_problem}), которое может быть выполнено одним из методов локальной оптимизации. Эффективность и проработанность методов локальной оптимизации позволяет решать подзадачи (\ref{local_problem}) с точностью, значительно превышающей точность методов глобальной оптимизации. Соответственно, можно рассматривать задачу (\ref{global_problem}) как задачу глобальной оптимизации, в которой значение функции может быть вычислено с высокой точностью, но данная операция является трудоемкой. 

В проведенном исследовании для решения задач глобальной оптимизации (\ref{global_problem}) мы использовали global search algorithm в сочетании со схемой редукции размерности на основе кривых Пеано [ссылки]. Данный алгорим зарекомендовал себя как мощный инструмент для решения сложных многоэкстремальных задач [ссылки].
Для решения локальной задачи (\ref{local_problem}) мы использовали Hooke-Jeevse pattern search method (see, e.g., \cite{Kelley}). В отличие от методов типа BFGS (see, e.g., \cite{Nocedal}), данный алгоритм не требует вычисления градиента и хорошо работает в условиях наличия вычислительных ошибок в значениях функций, что является типичным при решении прикладных задач.

\section{РАЗДЕЛЕНИЕ ПАРАМЕТРОВ ЗАДАЧИ}

Описать алгоритм разделения параметров и формирования подзадач для многошаговой схемы

\section{NUMERICAL EXPERIMENTS}

Описание тестовых задач

Описание результатов экспериментов

%\begin{figure}%[ht]
%\includegraphics[width=1.0\linewidth]{fig1.png}
%\caption{Schematic representation of the computational domain, with the geometry parameterization points marked in red and the black points independent of the optimization iterations. The grey lines show the possible deformation of the geometry.}
%\label{fig}
%\end{figure}

The calculation was carried out ...

% Acknowledgement
\section{ACKNOWLEDGMENTS}
This study was supported by the Russian Science Foundation, project No 21-11-00204.



% References

%\nocite{*}
\bibliographystyle{aipnum-cp}%
\bibliography{bibliography}%


\end{document}
