% interacttfssample.tex
% v1.05 - August 2017

\documentclass[]{interact}

%\usepackage{color}
\usepackage{hyperref}

\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
\usepackage[caption=false]{subfig}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required

%\usepackage[doublespacing]{setspace}% To produce a `double spaced' document if required
%\setlength\parindent{24pt}% To increase paragraph indentation when line spacing is doubled
%\setlength\bibindent{2em}% To increase hanging indent in bibliography when line spacing is doubled

\usepackage[numbers,sort&compress]{natbib}% Citation support using natbib.sty
\bibpunct[, ]{[}{]}{,}{n}{,}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

\begin{document}

%\articletype{ARTICLE TEMPLATE}% Specify the article type or omit as appropriate

\title{A fast algorithm for finding efficient decisions in multi-objective problems with black-box multiextremal functions}

\author{
\name{Konstantin Barkalov, Vladimir Grishagin and Evgeny Kozinov\thanks{CONTACT Evgeny Kozinov. Email: evgeny.kozinov@itmm.unn.ru}}
\affil{Software Department, Lobachevsky State University, Nizhni Novgorod, Russia}
}

\maketitle

\begin{abstract}
This template is for authors who are preparing a manuscript for a Taylor \& Francis journal using the \LaTeX\ document preparation system and the \texttt{interact} class file, which is available via selected journals' home pages on the Taylor \& Francis website.
\end{abstract}

\begin{keywords}
Multi-objective optimization; global optimization; dimensionality reduction; search information; nature-inspired metaheuristics; numerical comparison
\end{keywords}


\section{Introduction}

In the field of mathematical modeling the intelligent decision-making processes, the problems of multicriterial optimization (MCO) present a wide class of models that are rich and interesting from a theoretical point of view and very important in real applications \cite{Marler2009,Hillermeier2005}. Multicriterial problems describe decision-making situations with multiple goals which are considered as functional criteria to be optimized.

In general case, there exist three key factors determining the complexity of analyzing these models. The crucial feature corresponds to the typical case where criteria are contradictory: increasing one criterion leads to decreasing the other. Such inconsistent behavior generates the necessity of introducing a compromise in the joint analysis of criteria and consideration of a set of compromised (partial) solutions as a complete solution of a multiobjective problem (Pareto set), see, e.g., \cite{Collette2004,Ehrgott2005}.
The second complexity factor is associated with the dimensionality or number of varied parameters of the problem because increasing the problem dimension leads to significant growth of computational cost. 

Finally, the last factor is the multiextremality of criteria \cite{Pardalos2017}. First of all, multiextremal criteria can generate complicated Pareto sets consisting, for example, of several disconnected parts. Moreover, the combination of such factors as multiextremality and greater dimension leads to significant computational complexity of the problem because the computational cost increases exponentially when dimension grows. From this point of view the multiextremal problems are the most complicated ones in multicriterial optimization and this MCO class is the subject of interest in the given paper. 

The simplest way to build an approximation of the Pareto set consist in immersion in the feasible domain of problem's parameters a uniform grid (deterministic or random) and selection of all non-dominated nodes of the grid. Unfortunately, this universal approach is too costly because it requires in the worst case pairwise comparison of all the grid nodes and does not take into account the properties of the problem for reducing the computational costs.

Another idea applies a parameterization scheme for the criteria of the problem and reduces a MCO problem to a family of single-criterion (scalar) optimization problems being problems of mathematical programming which can be solved by corresponding well-developed optimization methods \cite{Collette2004,Ehrgott2005}. In this scheme a non-negative coefficient (weight) is assigned to each criterion which reflects numerically an ``importance'' of the criterion and on the base of such weighted criteria a scalar function (convolution) is built and minimized. Under appropriate choice of convolution the solution of the built scalar optimization problem is a partial solution of the initial multicriterial problem. Changing weights we can obtain different Pareto points. 

There exist various convolution functions but weighted sum function (linear convolution) and maximum from weighted criteria (maximum convolution) are most commonly used. The latter is more universal because it enables to build completely the Pareto set taking all the possible combinations of weights, whereas the linear convolution can lose Pareto points in non-convex case (in particular, if criteria are multiextremal).

For optimization of convolutions a wide spectrum of algorithms can be used in dependence on convolution properties generated by the features of criteria in the initial MCO problem. In particular, for the multiextremal case where it is required to find the global optimum the publications \cite{Evtushenko2014,Zilinskas2015,GERGEL2017_1,Gergel2019_2,Barkalov2021} describe applications of the global optimization algorithms to MCO problems in combination with the convolution approach.

Among other methods of solving MCO problems it is necessary to pay attention to the important class of metaheuristic nature-inspired algorithms. Many of them are nature-inspired, i.e.,  are  based on modeling physical processes (for example, simulated annealing \cite{Locatelli2002,Aarts2014}) or mainly behavior of biological agents including evolutionary \cite{Price2005,Coello2007} and as their part genetic algorithms \cite{Ruiz2015,Deb2002,Zitzler2001} and particle swarm methods modeling the swarming intelligence of bees, fireflies, birds, ants, etc. \cite{Mostaghim2007,Nebro2009,Durillo2010}.

Consideration of different approaches to solving MCO problems and a relevant references can be found, for example, in monographs and papers \cite{Miettinen1999,Ehrgott2005,Zhou2011,Nedjah2015,Pardalos2017}.
In this paper we consider multiextremal black-box MCO problems and propose a new scheme of solving these problems. This scheme is based on maximum convolution, dimensionality reduction by means of Peano curves, information-statistical global optimization algorithm used for the first time in MCO problems. Moreover, in the framework of the scheme the information already obtained in the course of solving scalar subproblems of convolution optimization can be utilized for solving a new convolution subproblem. Briefly, the way is as follows. Before beginning the optimization of a new convolution we have at our disposal values of criteria computed already and now can recalculate them to values of the current convolution taking into account these values as initial information for optimization algorithm. This procedure accelerates significantly the optimization process.

The quality of the proposed MCO method is experimentally studied on several multidimensional multiextremal test problems. Comparison with known evolutionary algorithms (2 particle swarm methods and 3 genetic algorithms have been taken) on the base of the hypervolume index \cite{Evtushenko2014,Zilinskas2015} reflecting quality of Pareto set estimation demonstrates qualitative results of the proposed method.

The rest of the paper is organized in the following manner. Section 2 considers the statement of the MCO problem to be studied. Section 3 is devoted to the description of the global search algorithm applied for scalar optimization of convolutions and the scheme of joint analyzing the family of ones. Section 4 contains results of computational experiments. The last Section concludes the paper.


\section{MCO problem statement}

The model of decision making to be considered hereinafter as the MCO problem consists in the following.

Let $w_i(x), 1 \leq i \leq k,$ be real-valued functions depending on vector of arguments $x=(x_1,...,x_N)$  and defined over the hyperparallelepiped 
\begin{equation}\label{Q}
Q = \left\{x \in R^N : a_j \leq x_j \leq b_j, 1 \leq i \leq N \right\}
\end{equation}
in $N$-dimensional Euclidean space $R^N$. These functions reflect objectives of decision making and it is considered that the less the function value, the better the result of achieving this objective.

The problem of multicriterial optimization is formulated as minimizing over the domain (\ref{Q}) the vector function
\begin{equation}\label{W}
W(x) = \left(w_1(x), ..., w_k(x)\right).
\end{equation}

This problem can be symbolically written as
\begin{equation}\label{problem}
W(x) \rightarrow \min , \; x \in Q.
\end{equation}

In terminology of decision making the vector function $W(x)$  is called \textit{vector criterion} of the problem, functions $w_i(x), 1 \leq i \leq k,$ are \textit{partial criteria} or \textit{objective functions}, $Q$ is the domain of feasible decisions or just the \textit{feasible domain} and points $x \in Q$ are \textit{feasible decisions}.

As a rule, each criterion attains its minimum at a point different from minimum points of other criteria, i.e., it is impossible to find out the decision $x^*$   providing in the region $Q$ minimum values for all the partial criteria simultaneously. This situation generates the contradictoriness of criteria, when decreasing one criterion leads to the growth of the other, and complicates the notion of optimal decision (solution to the problem (\ref{problem})).

Traditionally, optimal decisions in the problem (\ref{problem}) are defined on the base of Pareto optimality concept. To complete this item, let us give the known classical definitions concerning this concept.

\begin{definition} 
Let $x,z \in Q$. Vector $x$ is said to \textit{dominate} vector $z$ ($x \succ z$) if $w_i(x) \leq w_i(z), \; 1 \leq i \leq k,$ and there exists a number $p, \; 1 \leq p \leq k,$  such that $w_p(x) < w_p(z)$.
\end{definition}
\begin{definition} 
A decision vector $x^* \in Q$ is a \textit{Pareto optimal point} if in the domain $Q$ there is no vector $z \neq x^*$ dominating $x^*$.
\end{definition}
\begin{definition} 
The set of all Pareto optimal points (Pareto set $P$) is the \textit{Pareto optimal solution} to the MCO problem (\ref{problem}).
\end{definition}
\begin{definition} 
The set $F=W(P)=\left\{W(x):x \in P\right\}$  is called the \textit{Pareto front} of the problem (\ref{problem}).
\end{definition}

As mentioned in Introduction, one way of building the Pareto set consists in reducing the multiobjective problem to a family of single-criteria, or scalar optimization problems and solving them by methods of mathematical programming.  The global minimum point of a problem from this family will be a Pareto optimal point under corresponding assumptions. This approach can be realized by means of applying a convolution of the vector criterion (\ref{W}), for example, the maximum convolution
\begin{equation}\label{conv}
\Gamma(\lambda,x) = \max_{1 \leq i \leq k}{\lambda_i w_i(x)},
\end{equation}
where coefficients $\lambda_i, \; 1 \leq i \leq k,$ (weights of criteria) satisfy the conditions
\begin{equation}\label{lambda}
\lambda_i \geq 0, \; 1 \leq i \leq k, \; \sum_{i=1}^k{\lambda_i} = 1.
\end{equation}

If
\begin{equation}\label{positive}
w_i(x) > 0, \; 1 \leq i \leq k,
\end{equation}
in the domain (\ref{Q}), then global solution to the problem
\begin{equation}\label{conv_problem}
\Gamma(\lambda,x) + \gamma \sum_{i=1}^k{\lambda_i w_i(x)} \rightarrow \min, \; x \in Q,
\end{equation}
with a sufficiently small parameter $\gamma > 0$ is a Pareto optimal point of the initial MCO problem (\ref{problem}) \cite{Wierzbicki} [Wierzbicki, Krasnoshekov]. The positiveness of criteria is not restrictive requirement because it is possible to transform easily the MCO problem with non-positive criteria to the form (\ref{positive}) without loss of Pareto solution.

In the case of multiextremal criteria the problem (\ref{conv_problem}) is multiextremal as well and it is necessary to use global optimization algorithms for its solving. Many references to such the algorithms can be found in monographs \cite{Strongin2000,Pinter1996,Zhigljavsky2008,Sergeyev2013,PaulaviciusZilinskas2014,Sergeyev2017}. For solving multiextremal problems the information-statistical algorithms \cite{Strongin2000,Sergeyev2013} are among of the most efficient.

In the next section we describe an information-statistical algorithm with accelerated convergence and its application to searching for Pareto optimal solutions in multiextremal MCO problems.

\section{Algorithm}

\section{Numerical experiments}


\section*{Disclosure statement}

No potential conflict of interest was reported by the authors.

\section*{Funding}

This work was supported by the Russian Science Foundation, project No. 21-11-00204.



\bibliographystyle{tfs}
\bibliography{bibliography}

\end{document}
