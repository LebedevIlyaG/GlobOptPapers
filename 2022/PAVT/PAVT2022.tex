%%%%%%%%%%%%%%%%%%%% author.tex 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a proceedings volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{svproc}
%
% RECOMMENDED 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%
\usepackage{graphicx}
\usepackage{marvosym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cite}

\usepackage[russian]{babel}

% to typeset URLs, URIs, and DOIs
\usepackage{url}
\usepackage{hyperref}
\def\UrlFont{\rmfamily}

\def\orcidID#1{\unskip$^{[#1]}$}
\def\letter{$^{\textrm{(\Letter)}}$}

\begin{document}
\mainmatter              % start of a contribution
% Решение обратных задач химической кинетки с помощью асинхронного алгоритма глобального поиска
% Решение обратных задач химической кинетки с помощью смешанного локально-глобального поискового алгоритма 
\title{Solving the Inverse Problems of Chemical Kinetics Using the Asynchronous Global Optimization Algorithm}
%
\titlerunning{Solving the Inverse Problems of Chemical Kinetics}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{
Irek Gubaydullin$^{1,2}$\and
Leniza Enikeeva$^{2,3}$\orcidID{0000-0003-4219-4870}
\and
Konstantin Barkalov$^4$ \letter \orcidID{0000-0001-5273-2471}
\and
Ilya Lebedev$^4$\orcidID{0000-0002-8736-0652} 
}

%
\authorrunning{I. Gubaydullin et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
%\tocauthor{Konstantin Barkalov and Ilya Lebedev }
%

\institute{$^1$Institute of Petrochemistry and Catalysis – Subdivision of the Ufa Federal Research Centre of RAS, Ufa, Russia\\$^2$Ufa State Petroleum Technological University, Ufa, Russia \\$^3$Novosibirsk State University, Novosibirsk, Russia\\$^4$Lobachevsky State University of Nizhny Novgorod, Nizhny Novgorod, Russia\\
\email{leniza.enikeeva@yandex.ru},
\email{konstantin.barkalov@itmm.unn.ru},
\email{ilya.lebedev@itmm.unn.ru}
}

	
\maketitle              % typeset the title of the contribution

\begin{abstract}

The paper considers the application of parallel computing technology to the simulation of a catalytic chemical reaction, which is widely used in the modern chemical industry to produce synthesis gas. As a chemical reaction, the process of pre-reforming propane on a Ni catalyst is assumed. To simulate a chemical process, it is necessary to develop a kinetic model of the process, that is, to determine the kinetic parameters. To do this, the inverse problem of chemical kinetics is solved, which predicts the values of kinetic parameters based on laboratory data. From a mathematical point of view, the inverse problem of chemical kinetics is a global optimization problem. A parallel information-statistical global search algorithm was used to solve it. The use of the parallel algorithm has significantly reduced the search time to find the optimum. The found optimal parameters of the model made it possible to adequately simulate the process of pre-reforming propane on a Ni-catalyst.

%обновить ключевые слова
\keywords{Global optimization $\cdot$ Multiextremal functions $\cdot$ Parallel computing $\cdot$ Chemical kinetics $\cdot$ Inverse problems }
\end{abstract}

\section{Introduction}

%Часть УГНТУ

%Стыковочный абзац
Постоянно возрастающая сложность исследуемых реакций влечет за собой усложнение их математических моделей, что существенно затрудняет поиск кинетических констант. Как правило, найти кинетические константы реакций аналитическим путем не представляется возможным, поэтому возникает необходимость в разработке и использовании численных методов их поиска (см., например, [ссылки]). В этом случае критерий качества найденного решения (целевая функция) не имеет явного аналитического описания, но допускает алгоритмическое представление и требует значительных затрат на расчет. Кроме того, в обратных задачах химической кинетики целевая функция может быть существенно многоэкстремальной, т.е. иметь много локальных экстремумов наряду с глобальным. 

%Часть ННГУ
Численные методы решения подобных многоэкстремальных задач (методы глобальной оптимизации) существенно отличаются от методов локального поиска (see, e.g., \cite{Sergeyev2017,PaulaviciusZilinskas2014}). Как правило, методы локальной оптимизации не могут покинуть области притяжения локального экстремума и не находят глобальный оптимум. А использование параметров модели, соответствующих найденному локальному решению, может оказаться недостаточным, поскольку глобальное решение может дать существенный выигрыш по сравнению с локальным. 

Разнообразие возникающих задач глобальной оптимизации влечет за собой разнообразие подходов к их решению.
Методы решения задач глобальной оптмизации можно условно разделить на два класса: метаэвристические и детерминированные. Метаэвристические алгоритмы, как правило, основаны на имитации процессов, протекающих в живой природе.
Примерами метаэвристических алгоритмов являются simulated annealing, evolution and genetic algorithms и т.д. (see, e.g., \cite{Battiti2009,Eiben2015}). В силу своей относительной простоты метаэвристические алгоритмы более популярны у исследователей, чем детерминированные.  Однако решение задачи, найденное метаэвристическим алгоритмом, является, вообще говоря, локальным и может распологаться далеко от глобального \cite{Kvasov2018}. 

Возможность построения детерминированных методов глобального поиска, отличающихся от перебора по сетке и метаэвристических алгоритмов, связана с наличием и учетом  априорных предположений о свойствах функций задачи. Такие предположения играют ключевую роль при разработке эффективных алгоритмов глобальной оптимизации и служат основным математическим инструментом для получения оценок глобального решения.

Одним из естественных допущений о задаче является предположение об ограниченности относительных изменений значений целевой функции. Такое допущение связано с тем, что отношения приращений функции к соответствующим приращениям ее аргумента обычно не могут превышать некоторого порога, определяемого ограниченной энергией изменений в моделируемой системе. В таком случае, как известно, функции называются липшицевыми, а сама задача -- задачей липшицевой глобальной оптимизации. 

В данной статье отражены результаты применения параллельных методов липшицевой оптимизации, разрабатываемых в ННГУ им. Н.И. Лобачевского, к решению обратных задач химической кинетики. 
Основная часть статьи имеет следующую структуру. Описание математической модели исследуемой химической реакции приведено в Section 2. Формальная постановка задачи липшицевой глобальной оптимизации приводятся в Section 3. В Section 4 кратко изложена схема разрабатываемого авторами асинхронного параллельного алгоритма для решения задач указанного класса. Результаты численного решения обратной задачи химической кинетики обсуждаются в Section 5.


\section{Problem Statement}\label{Sec_math_mod}

%Содержательная постановка задачи


\section{}\label{Sec_GSA}

\subsection{Global Optimization Problem}

%Черновая заготовка для описания параллельного алгоритма оптимизации
Как уже говорилось выше, с формальной точки зрения the inverse problem of chemical kinetics рассматривается нами как Lipschitz global optimization problem. 
В общем виде задача указанного класса может быть математически сформулирована следующим образом:
\begin{gather}
 \varphi^* = \varphi(y^\ast)=\min{\left\{\varphi(y):y\in D\right\}}, \label{problemN}\\
 D=\left\{y\in R^N: a_i\leq y_i \leq b_i, \;  1\leq i \leq N\right\} \label{D},
\end{gather}
где $a,\; b$ есть заданные векторы, $a,b\in R^N$, а целевая функция $\varphi(y)$ удовлетворяет the Lipschitz condition
\begin{equation}\label{Lip}
\left|\varphi(y_1)-\varphi(y_2)\right|\leq L\left\|y_1-y_2\right\|,\; y_1,y_2 \in D.
\end{equation}

Функция $\varphi(y)$ предполагается многоэкстремальной и заданной в виде ``black box'' (т.е. в виде некоторой вычислительной процедуры, на вход которой подается вектор параметров, а на выходе наблюдается соответствующее значение функции). Кроме того, подразумевается, что каждое trial (т.е. вычисление значение функции в точке области поиска) является трудоемкой операцией и требует значительных вычислительных ресурсов. Как отмечалось во введении, такая постановка задачи полностью соответствует the inverse problem of chemical kinetics.

The Lipschitz condition (\ref{Lip}) может быть использовано для оценки глобального минимума функции на интервале, а знание константы Липшица позволяет конструировать алгоритмы глобального поиска и доказывать условия их сходимости (see, for example, [ссылки]).

Одной из основных трудностей в решении многомерных задач глобальной оптимизации является рост вычислительных затрат при увеличении размерности задачи. Уменьшение числа испытаний функции при сохранении точности решения возможно за счет более полного использования априорных предположений о целевой функции, что приводит к адаптивным последовательным алгоритмам оптимизации.

Такими методами являются, например, non-uniform space covering method \cite{Evtushenko2013} and simplicial partitions method \cite{Zilinskas2010}. Данные подходы были успешно использованы и для построения параллельных оптимизационных методов \cite{Evtushenko2009,Paulavicius2011}. Другим адаптивным подходом к решению многомерной задачи (\ref{problemN}) является ее редукция к одной или нескольким одномерным задачам с последующим применением одномерных алгоритмов. Такая редукция может быть осуществлена, например, при помощи nested optimization scheme \cite{Grishagin2018} или при помощи Peano-Hilbert curves \cite{Barkalov2018}. Последний из указанных подходов и используется в настоящей работе.

Используя непрерывное однозначное отображение (Peano-Hilbert curve) $y(x)$ отрезка $[0,1]$ вещественной оси на гиперинтервал $D$ из (\ref{D}) можно свести многомерную задачу (\ref{problemN}) к одномерной задаче
\[
\varphi(y^\ast)=\varphi(y(x^\ast))=\min{\left\{\varphi(y(x)): x\in[0,1]\right\}},
\]
where the function $\varphi(y(x))$ will satisfy a uniform H{\"o}lder condition
\[
\left|\varphi(y(x_1))-\varphi(y(x_2))\right|\leq H\left|x_1-x_2\right|^{1/N}
\]
with the H{\"o}lder constant $H$ linked to the Lipschitz constant $L$ by the relation $ H=2 L \sqrt{N+3}$.
Вопросы численного построения различных аппроксимаций Peano-Hilbert curve рассмотрены в \cite{Strongin2000,Sergeyev2013}.

Таким образом, поисковое испытание в некотрой точке $x'\in[0,1]$ будет включать в себя сначала the construction of the image $y'=y(x')$, и лишь затем вычисление значения функции $ z' = \varphi(y')$.

\subsection{Parallel Asynchronous Global Search Algorithm}

В предлагаемом подходе схема распараллеливания соответствует по принципу ``мастер-рабочие''. В процессе-мастере выполняется алгоритм глобального поиска, в котором проводится накопление поисковой информации, оценка на ее основе константы Липшица для целевой функции, определение точек новых испытаний и распределение их по процессам-рабочим. Процессы-рабочие получают от мастера точки, проводят в них новые испытания и отсылают мастеру результаты испытаний. 

Будем считать, что на каждой итерации процесс-мастер вычисляет одну точку нового испытания и передает ее для проведения испытания в процесс-рабочий. При этом проведение испытания рабочим является значительно более трудоемкой операцией, чем выбор новой точки мастером, что исключает простой процессов-рабочих. 
В данном случае (в отличие от синхронных параллельных алгоритмов) общее число выполненных испытаний каждым процессом-рабочим будет зависеть от трудоемкости проведения конкретного испытания и не может быть оценено заранее.

%комментарий про асинхронность? или ниже?
При описании параллельного алгоритма будем предполагать, что в нашем распоряжении имеется $p+1$ вычислительный процесс: один мастер и $p$ рабочих.
 
В начале поиска процесс-мастер (будем считать, что это процесс No 0) инициирует параллельное проведение $p$ испытаний в $p$ различных точках области поиска, две из которых являются граничными, а остальные -- внутренними, т.е. в точках $\{y(x^1), y(x^2), ...,y(x^p)\}$, где $x^1 = 0$, $x^p = 1$, $x^i\in(0,1), i=2,..., p-1$.

Предположим теперь, что выполнено $k$ испытаний (в частности, $k$ может быть равно 0), и процессы-рабочие проводят испытания в точках $\{y(x^{k+1}), y(x^{k+2}), ...,y(x^{k+p})\}$. 

Каждый процесс-рабочий, завершивший свое испытание в некоторой точке (не ограничивая общности, будем считать, что это точка $y(x^{k+1})$, соответствующая процессу No 1), пересылает процессу-мастеру результаты испытания. Мастер, в свою очередь, выбирает для него точку нового испытания $x^{k+p+1}$ в соответствии с правилами, описанными ниже.
Отметим, что в данном случае мы будем иметь set of preimages of the trial points
\[
I_k = \left\{ x^{k+1},x^{k+2},...,x^{k+p} \right\},
\]
в которых испытания уже начались, но еще не завершены.

Step 1. Перенумеровать в порядке возрастания (нижним идексом) set of preimages of the trial points 
\[
X_k = \left\{x^1, x^2,...,x^{k+p} \right\},
\]
которое содержит все preimages, в которых либо проведены, либо проводятся испытания, т.е.
\[
0=x_1<x_2<...<x_{x+p}=1.
\]
Step 2. Вычислить значения 
\[
M_1=\max \left\{ \frac{ \left|z_i - z_{i-1} \right|}{(x_i-x_{i-1})^{1/N}} : x_{i-1} \notin I_k, x_i \notin I_k, 2\leq i\leq k+p \right\},
\]
\[
M_2=\max \left\{ \frac{ \left|z_{i+1} - z_{i-1} \right|}{(x_{i+1}-x_{i-1})^{1/N}} : x_i \in I_k, 2\leq i < k+p \right\},
\]
\[
M=\max\{M_1,M_2\},
\]
где $z_i=\varphi(y(x_i))$, if $x_i \notin I_k, \; 1\leq i \leq k+p$. Значения $z_i$ в точках $x_i \in I_k$ являются неопределенными, т.к. испытания в точках $x_i \in I_k$ еще не завершены. Если значение $M$ получилось равным 0, то положить $M=1$.

Step 3. Каждому интервалу $(x_{i-1},x_i), \; x_{i-1} \notin I_k, x_i \notin I_k, \; 2\leq i\leq k+p$, поставить в соответствие число $R(i)$, которое называется характеристикой интервала и вычисляется по формуле
\[
R(i)=rM\Delta_i+\frac{(z_i-z_{i-1})^2}{rM\Delta_i}-2(z_i+z_{i-1}),
\]
где $\Delta_i=\left(x_i-x_{i-1}\right)^{1/N}$, and $r>1$ is the reliability parameter of the method.

Step 4. Выбрать интервал $[x_{t-1},x_t]$, которому соответствует максимальная характеристика, т.е.
\[
R(t) = \max \left\{ R(i): \; x_{i-1} \notin I_k, x_i \notin I_k, \; 2\leq i\leq k+p \right\}.
\]

Step 5. Определить точку нового испытания $y^{k+p+1}=y(x^{k+p+1})$, прообраз $x^{k+p+1} \in (x_{t-1},x_t)$ которой в соответствии с формулой
\[
x^{k+p+1} = \frac{x_{t}+x_{t-1}}{2} - \mathrm{sign}(z_{t}-z_{t-1})\frac{1}{2r}\left[\frac{\left|z_{t}-z_{t-1}\right|}{M}\right]^N.
\]


Сразу после вычисления точки очередного испытания процесс-мастер добавляет ее в множество $I_k$ и пересылает процессу-рабочему, который инициирует проведение испытания в ней. 

Процесс-мастер завершает работу алгоритма, если выполняется одно из двух условий: $\Delta_{t}<\epsilon$, $k+p>K_{max}$.
Вещественное число $\epsilon>0$ и целое число $K_{max}>0$ являются параметрами алгоритма и соответствуют точности поиска решения и максимальному числу испытаний.

Описанный параллельный асинхнонный алгоритм основан на последовательном information global search algorithm. Теоретическое обоснование сходимости алгоритма приведено в \cite{Strongin2000}. Здесь же приведены схемы синхронного распараллеливания, использовавшиеся ранее при решении ряда прикладных задач \cite{Kalyulin2017,Modorskii2016}.
Новизна данной работы заключается в практической реализации и применении асинхронной схемы распалаллеливания, обладающей большей эффективностью при решении задач с разной трудоемкостью проведения испытаний в разных точках области поиска. Это подтверждается результатами экспериментов, описанными в следующем разделе.

\section{Numerical Experiments}\label{Sec_Exp}




\section{Conclusions and Future Work}



\medskip

\textbf{Acknowledgments}. This study was supported by the Russian Science Foundation, project No.\,21-11-00204 and by RFBR, project No.\,19-37-60014.

%
% ---- Bibliography ----
%
\bibliographystyle{spmpsci}
\bibliography{bibliography}{}

\end{document}
